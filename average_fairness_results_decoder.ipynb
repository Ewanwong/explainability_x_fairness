{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "459f5259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from utils.vocabulary import *\n",
    "\n",
    "data = \"civil\"\n",
    "root_dir = f\"/scratch/yifwang/fairness_x_explainability/decoder_results_{data}\"\n",
    "\n",
    "\n",
    "models = ['qwen3_4b']# [\"llama_3b\", \"qwen_3b\", \"qwen3_4b\"]\n",
    "bias_types = [\"race\", \"gender\", \"religion\"]\n",
    "debiasing_methods = [\"zero_shot\", \"few_shot\", \"fairness_imagination\", \"fairness_instruction\"]\n",
    "\n",
    "if data == \"civil\":\n",
    "    num_examples = {\"race\": 2000, \"gender\": 2000, \"religion\": 1000}\n",
    "elif data == \"jigsaw\":\n",
    "    num_examples = {\"race\": 400, \"gender\": 800, \"religion\": 200}\n",
    "fairness_metrics = [\"model_accuracy\", \"accuracy\", \"fpr\", \"fnr\", \"individual_fairness\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af7e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_dict = {\"model\": [], \"bias_type\": [], \"debiasing_method\": [], \"fairness_metric\": [], \"score\": []}\n",
    "for model in models:\n",
    "    for bias_type in bias_types:\n",
    "        groups = SOCIAL_GROUPS[bias_type]\n",
    "        \n",
    "        for debiasing_method in debiasing_methods:\n",
    "            \n",
    "            file_path = os.path.join(root_dir, f\"{model}_{data}_{bias_type}_test_{num_examples[bias_type]}\", debiasing_method, \"fairness\", f\"fairness_{bias_type}_test_summary_stats.json\")\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"File not found: {file_path}\")\n",
    "                continue\n",
    "            with open(file_path, \"r\") as f:\n",
    "                fairness_data = json.load(f)\n",
    "            \n",
    "            for metric in fairness_metrics:\n",
    "                fairness_dict['model'].append(model)\n",
    "                fairness_dict['bias_type'].append(bias_type)\n",
    "                fairness_dict['debiasing_method'].append(debiasing_method)\n",
    "                if metric != \"individual_fairness\" and metric != \"model_accuracy\":\n",
    "                    fairness_dict['fairness_metric'].append(metric)\n",
    "                    fairness_dict['score'].append(round(sum([abs(fairness_data['Group_Fairness'][\"average\"][group][metric]) for group in groups])*100, 2))\n",
    "                elif metric == \"individual_fairness\":\n",
    "                    fairness_dict['fairness_metric'].append(\"individual_fairness\")\n",
    "                    fairness_dict['score'].append(round(fairness_data['Individual_Fairness']['overall'][\"predicted_class\"][\"abs_average\"]*100, 2))\n",
    "                elif metric == \"model_accuracy\":\n",
    "                    fairness_dict['fairness_metric'].append(\"model_accuracy\")\n",
    "                    fairness_dict['score'].append(round(fairness_data[\"Metrics\"][\"overall\"][\"accuracy\"] * 100, 2))\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6d82ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>bias_type</th>\n",
       "      <th>debiasing_method</th>\n",
       "      <th>fairness_metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>model_accuracy</td>\n",
       "      <td>69.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>fpr</td>\n",
       "      <td>7.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>fnr</td>\n",
       "      <td>13.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>individual_fairness</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>model_accuracy</td>\n",
       "      <td>63.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>fpr</td>\n",
       "      <td>10.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>fnr</td>\n",
       "      <td>8.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>individual_fairness</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>model_accuracy</td>\n",
       "      <td>71.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>fpr</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>fnr</td>\n",
       "      <td>11.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>individual_fairness</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>model_accuracy</td>\n",
       "      <td>70.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>fpr</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>fnr</td>\n",
       "      <td>11.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>race</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>individual_fairness</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>model_accuracy</td>\n",
       "      <td>79.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>fpr</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>fnr</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>individual_fairness</td>\n",
       "      <td>2.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>model_accuracy</td>\n",
       "      <td>76.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>fpr</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>fnr</td>\n",
       "      <td>7.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>individual_fairness</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>model_accuracy</td>\n",
       "      <td>80.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>fpr</td>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>fnr</td>\n",
       "      <td>9.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>individual_fairness</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>model_accuracy</td>\n",
       "      <td>79.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>fpr</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>fnr</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>gender</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>individual_fairness</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>model_accuracy</td>\n",
       "      <td>77.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>17.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>fpr</td>\n",
       "      <td>21.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>fnr</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>individual_fairness</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>model_accuracy</td>\n",
       "      <td>74.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>20.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>fpr</td>\n",
       "      <td>26.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>fnr</td>\n",
       "      <td>8.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>individual_fairness</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>model_accuracy</td>\n",
       "      <td>80.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>18.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>fpr</td>\n",
       "      <td>10.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>fnr</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>fairness_imagination</td>\n",
       "      <td>individual_fairness</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>model_accuracy</td>\n",
       "      <td>80.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>19.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>fpr</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>fnr</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>qwen3_4b</td>\n",
       "      <td>religion</td>\n",
       "      <td>fairness_instruction</td>\n",
       "      <td>individual_fairness</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model bias_type      debiasing_method      fairness_metric  score\n",
       "0   qwen3_4b      race             zero_shot       model_accuracy  69.55\n",
       "1   qwen3_4b      race             zero_shot             accuracy   0.60\n",
       "2   qwen3_4b      race             zero_shot                  fpr   7.13\n",
       "3   qwen3_4b      race             zero_shot                  fnr  13.25\n",
       "4   qwen3_4b      race             zero_shot  individual_fairness   2.55\n",
       "5   qwen3_4b      race              few_shot       model_accuracy  63.00\n",
       "6   qwen3_4b      race              few_shot             accuracy   1.90\n",
       "7   qwen3_4b      race              few_shot                  fpr  10.17\n",
       "8   qwen3_4b      race              few_shot                  fnr   8.04\n",
       "9   qwen3_4b      race              few_shot  individual_fairness   3.30\n",
       "10  qwen3_4b      race  fairness_imagination       model_accuracy  71.23\n",
       "11  qwen3_4b      race  fairness_imagination             accuracy   0.85\n",
       "12  qwen3_4b      race  fairness_imagination                  fpr   4.03\n",
       "13  qwen3_4b      race  fairness_imagination                  fnr  11.62\n",
       "14  qwen3_4b      race  fairness_imagination  individual_fairness   2.98\n",
       "15  qwen3_4b      race  fairness_instruction       model_accuracy  70.40\n",
       "16  qwen3_4b      race  fairness_instruction             accuracy   0.60\n",
       "17  qwen3_4b      race  fairness_instruction                  fpr   4.30\n",
       "18  qwen3_4b      race  fairness_instruction                  fnr  11.11\n",
       "19  qwen3_4b      race  fairness_instruction  individual_fairness   2.02\n",
       "20  qwen3_4b    gender             zero_shot       model_accuracy  79.75\n",
       "21  qwen3_4b    gender             zero_shot             accuracy   0.00\n",
       "22  qwen3_4b    gender             zero_shot                  fpr   1.40\n",
       "23  qwen3_4b    gender             zero_shot                  fnr   3.71\n",
       "24  qwen3_4b    gender             zero_shot  individual_fairness   2.41\n",
       "25  qwen3_4b    gender              few_shot       model_accuracy  76.40\n",
       "26  qwen3_4b    gender              few_shot             accuracy   1.60\n",
       "27  qwen3_4b    gender              few_shot                  fpr   4.77\n",
       "28  qwen3_4b    gender              few_shot                  fnr   7.21\n",
       "29  qwen3_4b    gender              few_shot  individual_fairness   4.03\n",
       "30  qwen3_4b    gender  fairness_imagination       model_accuracy  80.40\n",
       "31  qwen3_4b    gender  fairness_imagination             accuracy   1.00\n",
       "32  qwen3_4b    gender  fairness_imagination                  fpr   2.11\n",
       "33  qwen3_4b    gender  fairness_imagination                  fnr   9.21\n",
       "34  qwen3_4b    gender  fairness_imagination  individual_fairness   3.16\n",
       "35  qwen3_4b    gender  fairness_instruction       model_accuracy  79.77\n",
       "36  qwen3_4b    gender  fairness_instruction             accuracy   1.35\n",
       "37  qwen3_4b    gender  fairness_instruction                  fpr   0.39\n",
       "38  qwen3_4b    gender  fairness_instruction                  fnr   5.24\n",
       "39  qwen3_4b    gender  fairness_instruction  individual_fairness   1.83\n",
       "40  qwen3_4b  religion             zero_shot       model_accuracy  77.50\n",
       "41  qwen3_4b  religion             zero_shot             accuracy  17.40\n",
       "42  qwen3_4b  religion             zero_shot                  fpr  21.07\n",
       "43  qwen3_4b  religion             zero_shot                  fnr   5.17\n",
       "44  qwen3_4b  religion             zero_shot  individual_fairness   3.32\n",
       "45  qwen3_4b  religion              few_shot       model_accuracy  74.30\n",
       "46  qwen3_4b  religion              few_shot             accuracy  20.80\n",
       "47  qwen3_4b  religion              few_shot                  fpr  26.67\n",
       "48  qwen3_4b  religion              few_shot                  fnr   8.22\n",
       "49  qwen3_4b  religion              few_shot  individual_fairness   4.60\n",
       "50  qwen3_4b  religion  fairness_imagination       model_accuracy  80.83\n",
       "51  qwen3_4b  religion  fairness_imagination             accuracy  18.27\n",
       "52  qwen3_4b  religion  fairness_imagination                  fpr  10.51\n",
       "53  qwen3_4b  religion  fairness_imagination                  fnr   4.28\n",
       "54  qwen3_4b  religion  fairness_imagination  individual_fairness   2.20\n",
       "55  qwen3_4b  religion  fairness_instruction       model_accuracy  80.47\n",
       "56  qwen3_4b  religion  fairness_instruction             accuracy  19.33\n",
       "57  qwen3_4b  religion  fairness_instruction                  fpr   4.67\n",
       "58  qwen3_4b  religion  fairness_instruction                  fnr   5.08\n",
       "59  qwen3_4b  religion  fairness_instruction  individual_fairness   1.71"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to a pandas DataFrame\n",
    "import pandas as pd\n",
    "fairness_df = pd.DataFrame(fairness_dict)\n",
    "fairness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3873b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.40/79.77/80.47 & 0.60/\\textcolor{red}{1.35}/\\textcolor{red}{19.33} & \\textcolor{forestgreen}{4.30}/\\textcolor{forestgreen}{0.39}/\\textcolor{forestgreen}{4.67} & \\textcolor{forestgreen}{11.11}/\\textcolor{red}{5.24}/\\textcolor{forestgreen}{5.08} & \\textcolor{forestgreen}{2.02}/\\textcolor{forestgreen}{1.83}/\\textcolor{forestgreen}{1.71} \n"
     ]
    }
   ],
   "source": [
    "# 加color coding表示比较\n",
    "# print results as metric1_race/metric1_gender/metric1_religion metric2_race/ ...\n",
    "debiasing_method = \"fairness_instruction\"\n",
    "reported_metrics = [\"model_accuracy\", \"accuracy\", \"fpr\", \"fnr\", \"individual_fairness\"]\n",
    "bias_types_order = [\"race\", \"gender\", \"religion\"]\n",
    "print_string = \"\"\n",
    "for reported_metric in reported_metrics:\n",
    "    for bias_type in bias_types_order:\n",
    "        default_score = fairness_df[(fairness_df['debiasing_method'] == \"zero_shot\") & (fairness_df['bias_type'] == bias_type) & (fairness_df['fairness_metric'] == reported_metric)]['score'].values[0]\n",
    "        score = fairness_df[(fairness_df['debiasing_method'] == debiasing_method) & (fairness_df['bias_type'] == bias_type) & (fairness_df['fairness_metric'] == reported_metric)]['score'].values[0]\n",
    "        if debiasing_method != \"zero_shot\" and reported_metric != \"model_accuracy\":\n",
    "            if score < default_score:\n",
    "                print_string += \"\\\\textcolor{forestgreen}{\"\n",
    "                print_string += f\"{score:.2f}\" + \"}/\"\n",
    "            elif score > default_score:\n",
    "                print_string += \"\\\\textcolor{red}{\"\n",
    "                print_string += f\"{score:.2f}\" + \"}/\"\n",
    "            else:\n",
    "                print_string += f\"{score:.2f}\" + \"/\"\n",
    "        else:\n",
    "            print_string += f\"{score:.2f}\" + \"/\"\n",
    "    print_string = print_string[:-1] + \" & \"\n",
    "\n",
    "print(print_string[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "226594a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metric: accuracy\n",
      "\n",
      "Metric: accuracy, Model: llama_3b, Bias Type: race\n",
      "zero_shot: 0.014500000000000068\n",
      "few_shot: 0.011999999999999955\n",
      "fairness_imagination: 0.008000000000000007\n",
      "fairness_instruction: 0.026000000000000023\n",
      "\n",
      "Metric: accuracy, Model: llama_3b, Bias Type: gender\n",
      "zero_shot: 0.023499999999999965\n",
      "few_shot: 0.008999999999999952\n",
      "fairness_imagination: 0.008499999999999952\n",
      "fairness_instruction: 0.017000000000000015\n",
      "\n",
      "Metric: accuracy, Model: llama_3b, Bias Type: religion\n",
      "zero_shot: 0.2466666666666666\n",
      "few_shot: 0.21266666666666667\n",
      "fairness_imagination: 0.21866666666666668\n",
      "fairness_instruction: 0.21533333333333315\n",
      "\n",
      "Metric: accuracy, Model: qwen_3b, Bias Type: race\n",
      "zero_shot: 0.006000000000000005\n",
      "few_shot: 0.04799999999999993\n",
      "fairness_imagination: 0.017000000000000015\n",
      "fairness_instruction: 0.000500000000000056\n",
      "\n",
      "Metric: accuracy, Model: qwen_3b, Bias Type: gender\n",
      "zero_shot: 0.008499999999999952\n",
      "few_shot: 0.0040000000000000036\n",
      "fairness_imagination: 0.018500000000000072\n",
      "fairness_instruction: 0.014000000000000012\n",
      "\n",
      "Metric: accuracy, Model: qwen_3b, Bias Type: religion\n",
      "zero_shot: 0.19666666666666666\n",
      "few_shot: 0.19199999999999995\n",
      "fairness_imagination: 0.21133333333333337\n",
      "fairness_instruction: 0.19466666666666654\n",
      "\n",
      "Metric: accuracy, Model: qwen3_4b, Bias Type: race\n",
      "zero_shot: 0.006000000000000005\n",
      "few_shot: 0.018999999999999906\n",
      "fairness_imagination: 0.008500000000000063\n",
      "fairness_instruction: 0.006000000000000005\n",
      "\n",
      "Metric: accuracy, Model: qwen3_4b, Bias Type: gender\n",
      "zero_shot: 0.0\n",
      "few_shot: 0.016000000000000014\n",
      "fairness_imagination: 0.010000000000000009\n",
      "fairness_instruction: 0.013499999999999956\n",
      "\n",
      "Metric: accuracy, Model: qwen3_4b, Bias Type: religion\n",
      "zero_shot: 0.17400000000000004\n",
      "few_shot: 0.20799999999999996\n",
      "fairness_imagination: 0.18266666666666675\n",
      "fairness_instruction: 0.19333333333333347\n",
      "\n",
      "Metric: f1\n",
      "\n",
      "Metric: f1, Model: llama_3b, Bias Type: race\n",
      "zero_shot: 0.015701378254989184\n",
      "few_shot: 0.012175093244763846\n",
      "fairness_imagination: 0.0042174053225969566\n",
      "fairness_instruction: 0.008311826570772451\n",
      "\n",
      "Metric: f1, Model: llama_3b, Bias Type: gender\n",
      "zero_shot: 0.02165391150228113\n",
      "few_shot: 0.016668099116022128\n",
      "fairness_imagination: 0.0008835512474499874\n",
      "fairness_instruction: 0.044707665837248056\n",
      "\n",
      "Metric: f1, Model: llama_3b, Bias Type: religion\n",
      "zero_shot: 0.18943373303959854\n",
      "few_shot: 0.16068225036007838\n",
      "fairness_imagination: 0.16426382652490268\n",
      "fairness_instruction: 0.060727848683447716\n",
      "\n",
      "Metric: f1, Model: qwen_3b, Bias Type: race\n",
      "zero_shot: 0.049900531183605046\n",
      "few_shot: 0.032762422660225\n",
      "fairness_imagination: 0.020419609212457557\n",
      "fairness_instruction: 0.04090025474853021\n",
      "\n",
      "Metric: f1, Model: qwen_3b, Bias Type: gender\n",
      "zero_shot: 0.018455974896528504\n",
      "few_shot: 0.023291489667323195\n",
      "fairness_imagination: 0.05906026468058012\n",
      "fairness_instruction: 0.03355632913089801\n",
      "\n",
      "Metric: f1, Model: qwen_3b, Bias Type: religion\n",
      "zero_shot: 0.11841765062280896\n",
      "few_shot: 0.1383617798227692\n",
      "fairness_imagination: 0.13732639359875642\n",
      "fairness_instruction: 0.13462310240092346\n",
      "\n",
      "Metric: f1, Model: qwen3_4b, Bias Type: race\n",
      "zero_shot: 0.022722507797733105\n",
      "few_shot: 0.019873992923154282\n",
      "fairness_imagination: 0.03492847107960462\n",
      "fairness_instruction: 0.03758036409922849\n",
      "\n",
      "Metric: f1, Model: qwen3_4b, Bias Type: gender\n",
      "zero_shot: 0.003550386017695084\n",
      "few_shot: 0.007842301642161154\n",
      "fairness_imagination: 0.024084843477501394\n",
      "fairness_instruction: 0.02905455307207494\n",
      "\n",
      "Metric: f1, Model: qwen3_4b, Bias Type: religion\n",
      "zero_shot: 0.12199043432289092\n",
      "few_shot: 0.16684763597470698\n",
      "fairness_imagination: 0.09385074639476176\n",
      "fairness_instruction: 0.0792561820247859\n",
      "\n",
      "Metric: fpr\n",
      "\n",
      "Metric: fpr, Model: llama_3b, Bias Type: race\n",
      "zero_shot: 0.11028161176295392\n",
      "few_shot: 0.038744804198964866\n",
      "fairness_imagination: 0.08700990957803956\n",
      "fairness_instruction: 0.018943936294450056\n",
      "\n",
      "Metric: fpr, Model: llama_3b, Bias Type: gender\n",
      "zero_shot: 0.035231877324280236\n",
      "few_shot: 0.018213842112765\n",
      "fairness_imagination: 0.03612503031166875\n",
      "fairness_instruction: 0.003937277521606896\n",
      "\n",
      "Metric: fpr, Model: llama_3b, Bias Type: religion\n",
      "zero_shot: 0.3680687509754679\n",
      "few_shot: 0.3069448701031512\n",
      "fairness_imagination: 0.3253586529320791\n",
      "fairness_instruction: 0.06996630201904114\n",
      "\n",
      "Metric: fpr, Model: qwen_3b, Bias Type: race\n",
      "zero_shot: 0.040550108292119635\n",
      "few_shot: 0.09168776338237178\n",
      "fairness_imagination: 0.04675633097415881\n",
      "fairness_instruction: 0.033036281125820036\n",
      "\n",
      "Metric: fpr, Model: qwen_3b, Bias Type: gender\n",
      "zero_shot: 0.007615401844800557\n",
      "few_shot: 0.044599339899781765\n",
      "fairness_imagination: 0.024746353807053048\n",
      "fairness_instruction: 0.015712088200939986\n",
      "\n",
      "Metric: fpr, Model: qwen_3b, Bias Type: religion\n",
      "zero_shot: 0.07974644929695371\n",
      "few_shot: 0.2364872869932888\n",
      "fairness_imagination: 0.06255746392542458\n",
      "fairness_instruction: 0.09564327672072533\n",
      "\n",
      "Metric: fpr, Model: qwen3_4b, Bias Type: race\n",
      "zero_shot: 0.07129252980319312\n",
      "few_shot: 0.10167441301491009\n",
      "fairness_imagination: 0.04029276754946298\n",
      "fairness_instruction: 0.04304775042389375\n",
      "\n",
      "Metric: fpr, Model: qwen3_4b, Bias Type: gender\n",
      "zero_shot: 0.014040550071174579\n",
      "few_shot: 0.047673081942390255\n",
      "fairness_imagination: 0.021095070350837894\n",
      "fairness_instruction: 0.0038669359391804436\n",
      "\n",
      "Metric: fpr, Model: qwen3_4b, Bias Type: religion\n",
      "zero_shot: 0.21073837597014713\n",
      "few_shot: 0.26673321131117067\n",
      "fairness_imagination: 0.1050756963067013\n",
      "fairness_instruction: 0.046691425814781716\n",
      "\n",
      "Metric: fnr\n",
      "\n",
      "Metric: fnr, Model: llama_3b, Bias Type: race\n",
      "zero_shot: 0.10537368490132011\n",
      "few_shot: 0.008027023853109608\n",
      "fairness_imagination: 0.094417695373754\n",
      "fairness_instruction: 0.03787622356850251\n",
      "\n",
      "Metric: fnr, Model: llama_3b, Bias Type: gender\n",
      "zero_shot: 0.01031742641090272\n",
      "few_shot: 0.0019011406844106464\n",
      "fairness_imagination: 0.0679141567337406\n",
      "fairness_instruction: 0.06345680067216364\n",
      "\n",
      "Metric: fnr, Model: llama_3b, Bias Type: religion\n",
      "zero_shot: 0.029525544279642615\n",
      "few_shot: 0.016558244427096885\n",
      "fairness_imagination: 0.05981611588168964\n",
      "fairness_instruction: 0.04236880909012053\n",
      "\n",
      "Metric: fnr, Model: qwen_3b, Bias Type: race\n",
      "zero_shot: 0.130870883732497\n",
      "few_shot: 0.0325881970972845\n",
      "fairness_imagination: 0.08432174411616389\n",
      "fairness_instruction: 0.10745642818162349\n",
      "\n",
      "Metric: fnr, Model: qwen_3b, Bias Type: gender\n",
      "zero_shot: 0.04607596018285132\n",
      "few_shot: 0.13626265647028668\n",
      "fairness_imagination: 0.12960510388630186\n",
      "fairness_instruction: 0.0899161219578189\n",
      "\n",
      "Metric: fnr, Model: qwen_3b, Bias Type: religion\n",
      "zero_shot: 0.0935796686616358\n",
      "few_shot: 0.09457888802151102\n",
      "fairness_imagination: 0.149830861306271\n",
      "fairness_instruction: 0.13475843525023856\n",
      "\n",
      "Metric: fnr, Model: qwen3_4b, Bias Type: race\n",
      "zero_shot: 0.1324804332658658\n",
      "few_shot: 0.08043602904097097\n",
      "fairness_imagination: 0.11623296329812582\n",
      "fairness_instruction: 0.11105891780244681\n",
      "\n",
      "Metric: fnr, Model: qwen3_4b, Bias Type: gender\n",
      "zero_shot: 0.037097164665840676\n",
      "few_shot: 0.07208669771151083\n",
      "fairness_imagination: 0.09213767961151226\n",
      "fairness_instruction: 0.05239885504336306\n",
      "\n",
      "Metric: fnr, Model: qwen3_4b, Bias Type: religion\n",
      "zero_shot: 0.05172347992020121\n",
      "few_shot: 0.08220747679764073\n",
      "fairness_imagination: 0.04279816115881685\n",
      "fairness_instruction: 0.05084222395697802\n",
      "\n",
      "Metric: individual_fairness\n",
      "\n",
      "Metric: individual_fairness, Model: llama_3b, Bias Type: race\n",
      "zero_shot: 0.021278303116559982\n",
      "few_shot: 0.0010586145799607038\n",
      "fairness_imagination: 0.026465699076652527\n",
      "fairness_instruction: 0.013468890450894833\n",
      "\n",
      "Metric: individual_fairness, Model: llama_3b, Bias Type: gender\n",
      "zero_shot: 0.02937198244035244\n",
      "few_shot: 0.0012757903896272182\n",
      "fairness_imagination: 0.035843126475811005\n",
      "fairness_instruction: 0.011334670707583427\n",
      "\n",
      "Metric: individual_fairness, Model: llama_3b, Bias Type: religion\n",
      "zero_shot: 0.03834236040711403\n",
      "few_shot: 0.0032715145498514175\n",
      "fairness_imagination: 0.03495153412222862\n",
      "fairness_instruction: 0.017130298539996147\n",
      "\n",
      "Metric: individual_fairness, Model: qwen_3b, Bias Type: race\n",
      "zero_shot: 0.01783020608127117\n",
      "few_shot: 0.0031945407390594482\n",
      "fairness_imagination: 0.02270589768886566\n",
      "fairness_instruction: 0.018903667107224464\n",
      "\n",
      "Metric: individual_fairness, Model: qwen_3b, Bias Type: gender\n",
      "zero_shot: 0.01813017576932907\n",
      "few_shot: 0.0032204068265855312\n",
      "fairness_imagination: 0.032019756734371185\n",
      "fairness_instruction: 0.023843172937631607\n",
      "\n",
      "Metric: individual_fairness, Model: qwen_3b, Bias Type: religion\n",
      "zero_shot: 0.019138991832733154\n",
      "few_shot: 0.009639648720622063\n",
      "fairness_imagination: 0.025081919506192207\n",
      "fairness_instruction: 0.022996170446276665\n",
      "\n",
      "Metric: individual_fairness, Model: qwen3_4b, Bias Type: race\n",
      "zero_shot: 0.02552705630660057\n",
      "few_shot: 0.03302416577935219\n",
      "fairness_imagination: 0.029793398454785347\n",
      "fairness_instruction: 0.020247377455234528\n",
      "\n",
      "Metric: individual_fairness, Model: qwen3_4b, Bias Type: gender\n",
      "zero_shot: 0.024075713008642197\n",
      "few_shot: 0.04026708006858826\n",
      "fairness_imagination: 0.03162149712443352\n",
      "fairness_instruction: 0.01834414154291153\n",
      "\n",
      "Metric: individual_fairness, Model: qwen3_4b, Bias Type: religion\n",
      "zero_shot: 0.0332028865814209\n",
      "few_shot: 0.04597564414143562\n",
      "fairness_imagination: 0.02200203388929367\n",
      "fairness_instruction: 0.017087025567889214\n"
     ]
    }
   ],
   "source": [
    "# print out each metric for different debiasing methods, for all models and bias types\n",
    "for metric in fairness_metrics:\n",
    "    print(f\"\\nMetric: {metric}\")\n",
    "    for model in models:\n",
    "        for bias_type in bias_types:\n",
    "            print(f\"\\nMetric: {metric}, Model: {model}, Bias Type: {bias_type}\")\n",
    "            for debiasing_method in debiasing_methods:\n",
    "                subset = fairness_df[(fairness_df['model'] == model) & (fairness_df['bias_type'] == bias_type) & (fairness_df['debiasing_method'] == debiasing_method) & (fairness_df['fairness_metric'] == metric)]\n",
    "                if not subset.empty:\n",
    "                    print(f\"{debiasing_method}: {subset['score'].values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660da568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fairness score for accuracy:\n",
      "  bias_type     score\n",
      "0    gender  0.011875\n",
      "1      race  0.014292\n",
      "2  religion  0.203833\n",
      "Average fairness score for f1:\n",
      "  bias_type     score\n",
      "0    gender  0.023567\n",
      "1      race  0.024958\n",
      "2  religion  0.130482\n",
      "Average fairness score for fpr:\n",
      "  bias_type     score\n",
      "0    gender  0.022738\n",
      "1      race  0.060277\n",
      "2  religion  0.181168\n",
      "Average fairness score for fnr:\n",
      "  bias_type     score\n",
      "0    gender  0.066597\n",
      "1      race  0.086762\n",
      "2  religion  0.070716\n",
      "Average fairness score for individual_fairness:\n",
      "  bias_type     score\n",
      "0    gender  0.022446\n",
      "1      race  0.019458\n",
      "2  religion  0.024068\n"
     ]
    }
   ],
   "source": [
    "# show the average fairness score for each bias type\n",
    "for metric in fairness_metrics:\n",
    "    print(f\"Average fairness score for {metric}:\")\n",
    "    avg_score = fairness_df[fairness_df['fairness_metric'] == metric].groupby(['bias_type'])['score'].mean().reset_index()\n",
    "    print(avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e9136c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: llama_3b, Bias Type: race\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot               0.0145  0.015701  0.105374  0.110282   \n",
      "few_shot                0.0120  0.012175  0.008027  0.038745   \n",
      "fairness_imagination    0.0080  0.004217  0.094418  0.087010   \n",
      "fairness_instruction    0.0260  0.008312  0.037876  0.018944   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.021278  \n",
      "few_shot                         0.001059  \n",
      "fairness_imagination             0.026466  \n",
      "fairness_instruction             0.013469  \n",
      "\n",
      "\n",
      "\n",
      "Model: qwen_3b, Bias Type: race\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot               0.0060  0.049901  0.130871  0.040550   \n",
      "few_shot                0.0480  0.032762  0.032588  0.091688   \n",
      "fairness_imagination    0.0170  0.020420  0.084322  0.046756   \n",
      "fairness_instruction    0.0005  0.040900  0.107456  0.033036   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.017830  \n",
      "few_shot                         0.003195  \n",
      "fairness_imagination             0.022706  \n",
      "fairness_instruction             0.018904  \n",
      "\n",
      "\n",
      "\n",
      "Model: qwen3_4b, Bias Type: race\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot               0.0060  0.022723  0.132480  0.071293   \n",
      "few_shot                0.0190  0.019874  0.080436  0.101674   \n",
      "fairness_imagination    0.0085  0.034928  0.116233  0.040293   \n",
      "fairness_instruction    0.0060  0.037580  0.111059  0.043048   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.025527  \n",
      "few_shot                         0.033024  \n",
      "fairness_imagination             0.029793  \n",
      "fairness_instruction             0.020247  \n",
      "\n",
      "\n",
      "\n",
      "Model: llama_3b, Bias Type: gender\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot               0.0235  0.021654  0.010317  0.035232   \n",
      "few_shot                0.0090  0.016668  0.001901  0.018214   \n",
      "fairness_imagination    0.0085  0.000884  0.067914  0.036125   \n",
      "fairness_instruction    0.0170  0.044708  0.063457  0.003937   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.029372  \n",
      "few_shot                         0.001276  \n",
      "fairness_imagination             0.035843  \n",
      "fairness_instruction             0.011335  \n",
      "\n",
      "\n",
      "\n",
      "Model: qwen_3b, Bias Type: gender\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot               0.0085  0.018456  0.046076  0.007615   \n",
      "few_shot                0.0040  0.023291  0.136263  0.044599   \n",
      "fairness_imagination    0.0185  0.059060  0.129605  0.024746   \n",
      "fairness_instruction    0.0140  0.033556  0.089916  0.015712   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.018130  \n",
      "few_shot                         0.003220  \n",
      "fairness_imagination             0.032020  \n",
      "fairness_instruction             0.023843  \n",
      "\n",
      "\n",
      "\n",
      "Model: qwen3_4b, Bias Type: gender\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot               0.0000  0.003550  0.037097  0.014041   \n",
      "few_shot                0.0160  0.007842  0.072087  0.047673   \n",
      "fairness_imagination    0.0100  0.024085  0.092138  0.021095   \n",
      "fairness_instruction    0.0135  0.029055  0.052399  0.003867   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.024076  \n",
      "few_shot                         0.040267  \n",
      "fairness_imagination             0.031621  \n",
      "fairness_instruction             0.018344  \n",
      "\n",
      "\n",
      "\n",
      "Model: llama_3b, Bias Type: religion\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot             0.246667  0.189434  0.029526  0.368069   \n",
      "few_shot              0.212667  0.160682  0.016558  0.306945   \n",
      "fairness_imagination  0.218667  0.164264  0.059816  0.325359   \n",
      "fairness_instruction  0.215333  0.060728  0.042369  0.069966   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.038342  \n",
      "few_shot                         0.003272  \n",
      "fairness_imagination             0.034952  \n",
      "fairness_instruction             0.017130  \n",
      "\n",
      "\n",
      "\n",
      "Model: qwen_3b, Bias Type: religion\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot             0.196667  0.118418  0.093580  0.079746   \n",
      "few_shot              0.192000  0.138362  0.094579  0.236487   \n",
      "fairness_imagination  0.211333  0.137326  0.149831  0.062557   \n",
      "fairness_instruction  0.194667  0.134623  0.134758  0.095643   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.019139  \n",
      "few_shot                         0.009640  \n",
      "fairness_imagination             0.025082  \n",
      "fairness_instruction             0.022996  \n",
      "\n",
      "\n",
      "\n",
      "Model: qwen3_4b, Bias Type: religion\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot             0.174000  0.121990  0.051723  0.210738   \n",
      "few_shot              0.208000  0.166848  0.082207  0.266733   \n",
      "fairness_imagination  0.182667  0.093851  0.042798  0.105076   \n",
      "fairness_instruction  0.193333  0.079256  0.050842  0.046691   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.033203  \n",
      "few_shot                         0.045976  \n",
      "fairness_imagination             0.022002  \n",
      "fairness_instruction             0.017087  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show for each debiasing method, what is there average fairness score (across model types and bias types) for each metric and training type, show in one table, where each row is a debiasing method, and each column is a metric and training type\n",
    "\n",
    "for bias_type in bias_types:\n",
    "    for model in models:\n",
    "        print(f\"\\nModel: {model}, Bias Type: {bias_type}\")\n",
    "        avg_score = fairness_df[(fairness_df['model'] == model) & (fairness_df['bias_type'] == bias_type)].groupby(['debiasing_method', 'fairness_metric'])['score'].mean().unstack().reset_index()\n",
    "        \n",
    "\n",
    "        # show the difference in the average fairness score for each debiasing method compared to no debiasing\n",
    "        #avg_score = fairness_df.groupby(['debiasing_method', 'fairness_metric'])['score'].mean().unstack().reset_index()\n",
    "        avg_score = avg_score.set_index('debiasing_method')\n",
    "        avg_score = avg_score.reindex(debiasing_methods)\n",
    "        print(avg_score)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2556fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: llama_3b, Bias Type: race\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot               0.0000  0.000000  0.000000  0.000000   \n",
      "few_shot               -0.0025 -0.003526 -0.097347 -0.071537   \n",
      "fairness_imagination   -0.0065 -0.011484 -0.010956 -0.023272   \n",
      "fairness_instruction    0.0115 -0.007390 -0.067497 -0.091338   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.000000  \n",
      "few_shot                        -0.020220  \n",
      "fairness_imagination             0.005187  \n",
      "fairness_instruction            -0.007809  \n",
      "\n",
      "\n",
      "\n",
      "Model: qwen_3b, Bias Type: race\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot               0.0000  0.000000  0.000000  0.000000   \n",
      "few_shot                0.0420 -0.017138 -0.098283  0.051138   \n",
      "fairness_imagination    0.0110 -0.029481 -0.046549  0.006206   \n",
      "fairness_instruction   -0.0055 -0.009000 -0.023414 -0.007514   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.000000  \n",
      "few_shot                        -0.014636  \n",
      "fairness_imagination             0.004876  \n",
      "fairness_instruction             0.001073  \n",
      "\n",
      "\n",
      "\n",
      "Model: qwen3_4b, Bias Type: race\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot               0.0000  0.000000  0.000000  0.000000   \n",
      "few_shot                0.0130 -0.002849 -0.052044  0.030382   \n",
      "fairness_imagination    0.0025  0.012206 -0.016247 -0.031000   \n",
      "fairness_instruction    0.0000  0.014858 -0.021422 -0.028245   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.000000  \n",
      "few_shot                         0.007497  \n",
      "fairness_imagination             0.004266  \n",
      "fairness_instruction            -0.005280  \n",
      "\n",
      "\n",
      "\n",
      "Model: llama_3b, Bias Type: gender\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot               0.0000  0.000000  0.000000  0.000000   \n",
      "few_shot               -0.0145 -0.004986 -0.008416 -0.017018   \n",
      "fairness_imagination   -0.0150 -0.020770  0.057597  0.000893   \n",
      "fairness_instruction   -0.0065  0.023054  0.053139 -0.031295   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.000000  \n",
      "few_shot                        -0.028096  \n",
      "fairness_imagination             0.006471  \n",
      "fairness_instruction            -0.018037  \n",
      "\n",
      "\n",
      "\n",
      "Model: qwen_3b, Bias Type: gender\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot               0.0000  0.000000  0.000000  0.000000   \n",
      "few_shot               -0.0045  0.004836  0.090187  0.036984   \n",
      "fairness_imagination    0.0100  0.040604  0.083529  0.017131   \n",
      "fairness_instruction    0.0055  0.015100  0.043840  0.008097   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.000000  \n",
      "few_shot                        -0.014910  \n",
      "fairness_imagination             0.013890  \n",
      "fairness_instruction             0.005713  \n",
      "\n",
      "\n",
      "\n",
      "Model: qwen3_4b, Bias Type: gender\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot               0.0000  0.000000  0.000000  0.000000   \n",
      "few_shot                0.0160  0.004292  0.034990  0.033633   \n",
      "fairness_imagination    0.0100  0.020534  0.055041  0.007055   \n",
      "fairness_instruction    0.0135  0.025504  0.015302 -0.010174   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.000000  \n",
      "few_shot                         0.016191  \n",
      "fairness_imagination             0.007546  \n",
      "fairness_instruction            -0.005732  \n",
      "\n",
      "\n",
      "\n",
      "Model: llama_3b, Bias Type: religion\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot             0.000000  0.000000  0.000000  0.000000   \n",
      "few_shot             -0.034000 -0.028751 -0.012967 -0.061124   \n",
      "fairness_imagination -0.028000 -0.025170  0.030291 -0.042710   \n",
      "fairness_instruction -0.031333 -0.128706  0.012843 -0.298102   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.000000  \n",
      "few_shot                        -0.035071  \n",
      "fairness_imagination            -0.003391  \n",
      "fairness_instruction            -0.021212  \n",
      "\n",
      "\n",
      "\n",
      "Model: qwen_3b, Bias Type: religion\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot             0.000000  0.000000  0.000000  0.000000   \n",
      "few_shot             -0.004667  0.019944  0.000999  0.156741   \n",
      "fairness_imagination  0.014667  0.018909  0.056251 -0.017189   \n",
      "fairness_instruction -0.002000  0.016205  0.041179  0.015897   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.000000  \n",
      "few_shot                        -0.009499  \n",
      "fairness_imagination             0.005943  \n",
      "fairness_instruction             0.003857  \n",
      "\n",
      "\n",
      "\n",
      "Model: qwen3_4b, Bias Type: religion\n",
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot             0.000000  0.000000  0.000000  0.000000   \n",
      "few_shot              0.034000  0.044857  0.030484  0.055995   \n",
      "fairness_imagination  0.008667 -0.028140 -0.008925 -0.105663   \n",
      "fairness_instruction  0.019333 -0.042734 -0.000881 -0.164047   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.000000  \n",
      "few_shot                         0.012773  \n",
      "fairness_imagination            -0.011201  \n",
      "fairness_instruction            -0.016116  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show for each debiasing method, what is there average fairness score (across model types and bias types) for each metric and training type, show in one table, where each row is a debiasing method, and each column is a metric and training type\n",
    "\n",
    "for bias_type in bias_types:\n",
    "    for model in models:\n",
    "        print(f\"\\nModel: {model}, Bias Type: {bias_type}\")\n",
    "        avg_score = fairness_df[(fairness_df['model'] == model) & (fairness_df['bias_type'] == bias_type)].groupby(['debiasing_method', 'fairness_metric'])['score'].mean().unstack().reset_index()\n",
    "        \n",
    "\n",
    "        # show the difference in the average fairness score for each debiasing method compared to no debiasing\n",
    "        #avg_score = fairness_df.groupby(['debiasing_method', 'fairness_metric'])['score'].mean().unstack().reset_index()\n",
    "        avg_score = avg_score.set_index('debiasing_method')\n",
    "        avg_score = avg_score.reindex(debiasing_methods)\n",
    "        no_debiasing_scores = avg_score.loc['zero_shot']\n",
    "        for metric in avg_score.columns:\n",
    "            if metric != 'debiasing_method':\n",
    "                avg_score[metric] = avg_score[metric] - no_debiasing_scores[metric]\n",
    "        print(avg_score)\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad2699cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot             0.075093  0.062425  0.070783  0.104174   \n",
      "few_shot              0.080074  0.064278  0.058294  0.128084   \n",
      "fairness_imagination  0.075907  0.059893  0.093008  0.083224   \n",
      "fairness_instruction  0.075593  0.052080  0.076681  0.036761   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.025211  \n",
      "few_shot                         0.015659  \n",
      "fairness_imagination             0.028943  \n",
      "fairness_instruction             0.018151  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show for each debiasing method, what is there average fairness score (across model types and bias types) for each metric and training type, show in one table, where each row is a debiasing method, and each column is a metric and training type\n",
    "\n",
    "avg_score = fairness_df.groupby(['debiasing_method', 'fairness_metric'])['score'].mean().unstack().reset_index()\n",
    "\n",
    "\n",
    "# show the difference in the average fairness score for each debiasing method compared to no debiasing\n",
    "#avg_score = fairness_df.groupby(['debiasing_method', 'fairness_metric'])['score'].mean().unstack().reset_index()\n",
    "avg_score = avg_score.set_index('debiasing_method')\n",
    "avg_score = avg_score.reindex(debiasing_methods)\n",
    "print(avg_score)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d89ed6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairness_metric       accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                               \n",
      "zero_shot             0.000000  0.000000  0.000000  0.000000   \n",
      "few_shot              0.004981  0.001853 -0.012489  0.023910   \n",
      "fairness_imagination  0.000815 -0.002532  0.022226 -0.020950   \n",
      "fairness_instruction  0.000500 -0.010345  0.005899 -0.067413   \n",
      "\n",
      "fairness_metric       individual_fairness  \n",
      "debiasing_method                           \n",
      "zero_shot                        0.000000  \n",
      "few_shot                        -0.009552  \n",
      "fairness_imagination             0.003732  \n",
      "fairness_instruction            -0.007060  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show for each debiasing method, what is there average fairness score (across model types and bias types) for each metric and training type, show in one table, where each row is a debiasing method, and each column is a metric and training type\n",
    "\n",
    "\n",
    "avg_score = fairness_df.groupby(['debiasing_method', 'fairness_metric'])['score'].mean().unstack().reset_index()\n",
    "\n",
    "\n",
    "# show the difference in the average fairness score for each debiasing method compared to no debiasing\n",
    "#avg_score = fairness_df.groupby(['debiasing_method', 'fairness_metric'])['score'].mean().unstack().reset_index()\n",
    "avg_score = avg_score.set_index('debiasing_method')\n",
    "avg_score = avg_score.reindex(debiasing_methods)\n",
    "no_debiasing_scores = avg_score.loc['zero_shot']\n",
    "for metric in avg_score.columns:\n",
    "    if metric != 'debiasing_method':\n",
    "        avg_score[metric] = avg_score[metric] - no_debiasing_scores[metric]\n",
    "print(avg_score)\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
