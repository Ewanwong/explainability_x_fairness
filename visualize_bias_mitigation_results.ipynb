{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b11b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from utils.vocabulary import *\n",
    "\n",
    "data = \"civil\"  # \"civil\" or \"jigsaw\"\n",
    "root_dir = f\"/scratch/yifwang/fairness_x_explainability/encoder_results_{data}\"\n",
    "debiased_dir = f\"/scratch/yifwang/fairness_x_explainability/bias_mitigation_results_{data}\"\n",
    "\n",
    "\n",
    "models = [\"bert\"] # roberta gender有一个有问题，distilbert的attention都有问题\n",
    "bias_types = [\"race\", \"gender\", \"religion\"]\n",
    "\n",
    "debiasing_methods = [\"no_debiasing\", \"group_balance\", \"group_class_balance\", \"cda\", \"dropout\", \"attention_entropy\", \"causal_debias\"]\n",
    "\n",
    "#explanation_methods = [\"Saliency\", \"InputXGradient\", \"IntegratedGradients\", \"raw_attention\", \"attention_rollout\", \"attention_flow\", \"Occlusion\"]\n",
    "explanation_methods = [\"Saliency\", \"InputXGradient\", \"raw_attention\", \"attention_rollout\", \"attention_flow\", \"Occlusion\"]\n",
    "\n",
    "aggregation = [\"L1\", \"L2\"]\n",
    "seeds = [1, 2, 42]\n",
    "alphas = [100.0, 10.0, 1.0, 0.1, 0.01]\n",
    "\n",
    "training_types = [\"one axis\"] # [\"all axes\", \"one axis\"]\n",
    "if data == \"civil\":\n",
    "    num_examples = {\"race\": 2000, \"gender\": 2000, \"religion\": 1000}\n",
    "elif data == \"jigsaw\":\n",
    "    num_examples = {\"race\": 400, \"gender\": 800, \"religion\": 200}\n",
    "    \n",
    "fairness_metrics = [\"accuracy\", \"f1\", \"fpr\", \"fnr\", \"individual_fairness\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb205ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_dict = {\"model\": [], \"bias_type\": [], \"debiasing_method\": [], \"training_data\": [], \"seed\": [], \"fairness_metric\": [], \"score\": []}\n",
    "for model in models:\n",
    "    for bias_type in bias_types:\n",
    "        groups = SOCIAL_GROUPS[bias_type]\n",
    "        # load baseline fairness results\n",
    "        for training_type in training_types:\n",
    "            data_token = \"all\" if training_type == \"all axes\" else bias_type\n",
    "            for debiasing_method in debiasing_methods:\n",
    "                \n",
    "                file_path = os.path.join(root_dir, f\"{model}_{data}_{data_token}_{bias_type}_test_{num_examples[bias_type]}\", debiasing_method, \"fairness\", f\"fairness_{bias_type}_test_summary_stats.json\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    print(f\"File not found: {file_path}\")\n",
    "                    continue\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    fairness_data = json.load(f)\n",
    "                \n",
    "                for metric in fairness_metrics:\n",
    "                    fairness_dict['model'].append(model)\n",
    "                    fairness_dict['bias_type'].append(bias_type)\n",
    "                    fairness_dict['seed'].append(-1)\n",
    "                    fairness_dict['debiasing_method'].append(debiasing_method)\n",
    "                    fairness_dict['training_data'].append(training_type)\n",
    "                    if metric != \"individual_fairness\":\n",
    "                        fairness_dict['fairness_metric'].append(metric)\n",
    "                        fairness_dict['score'].append(sum([abs(fairness_data['Group_Fairness'][\"average\"][group][metric]) for group in groups]))\n",
    "                    else:\n",
    "                        fairness_dict['fairness_metric'].append(\"individual_fairness\")\n",
    "                        fairness_dict['score'].append(fairness_data['Individual_Fairness']['overall'][\"predicted_class\"][\"abs_average\"])\n",
    "            for seed in seeds:\n",
    "                for explanation_method in explanation_methods:\n",
    "                    if explanation_method in [\"raw_attention\", \"attention_rollout\", \"attention_flow\", \"Occlusion\"]:\n",
    "                        aggregation = [\"none\"]\n",
    "                    else:\n",
    "                        aggregation = [\"L1\", \"L2\"]\n",
    "                    for aggregation_method in aggregation:\n",
    "                        for alpha in alphas:\n",
    "                            if explanation_method in [\"raw_attention\", \"attention_rollout\", \"attention_flow\", \"Occlusion\"]:\n",
    "                                file_path = os.path.join(debiased_dir, f\"{model}_{data}_{data_token}_{bias_type}_test_{num_examples[bias_type]}_{seed}\", explanation_method, f\"{alpha}\",\"fairness\", f\"fairness_{bias_type}_test_summary_stats.json\")\n",
    "                            else:\n",
    "                                file_path = os.path.join(debiased_dir, f\"{model}_{data}_{data_token}_{bias_type}_test_{num_examples[bias_type]}_{seed}\", explanation_method, f\"{aggregation_method}_{alpha}\",\"fairness\", f\"fairness_{bias_type}_test_summary_stats.json\")\n",
    "                            if not os.path.exists(file_path):\n",
    "                                print(f\"File not found: {file_path}\")\n",
    "                                continue\n",
    "                            with open(file_path, \"r\") as f:\n",
    "                                explanation_data = json.load(f)\n",
    "                            \n",
    "                            for metric in fairness_metrics:\n",
    "                                fairness_dict['model'].append(model)\n",
    "                                fairness_dict['bias_type'].append(bias_type)\n",
    "                                fairness_dict['seed'].append(seed)\n",
    "                                if explanation_method in [\"raw_attention\", \"attention_rollout\", \"attention_flow\", \"Occlusion\"]:\n",
    "                                    fairness_dict['debiasing_method'].append(f\"{explanation_method}_{alpha}\")\n",
    "                                else:\n",
    "                                    fairness_dict['debiasing_method'].append(f\"{explanation_method}_{aggregation_method}_{alpha}\")\n",
    "                                fairness_dict['training_data'].append(training_type)\n",
    "                                fairness_dict['fairness_metric'].append(metric)\n",
    "                                if metric != \"individual_fairness\":\n",
    "                                    fairness_dict['score'].append(sum([abs(explanation_data['Group_Fairness'][\"average\"][group][metric]) for group in groups]))\n",
    "                                else:\n",
    "                                    fairness_dict['score'].append(explanation_data['Individual_Fairness']['overall'][\"predicted_class\"][\"abs_average\"])\n",
    "\n",
    "# convert to a pandas DataFrame\n",
    "import pandas as pd\n",
    "fairness_df = pd.DataFrame(fairness_dict)\n",
    "# fairness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb4eb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print out each metric for different debiasing methods, for all models and bias types\n",
    "# for metric in fairness_metrics:\n",
    "#     print(f\"\\nMetric: {metric}\")\n",
    "#     for model in models:\n",
    "#         for bias_type in bias_types:\n",
    "#             print(f\"\\nMetric: {metric}, Model: {model}, Bias Type: {bias_type}\")\n",
    "#             for debiasing_method in fairness_df['debiasing_method'].unique():\n",
    "#                 subset = fairness_df[(fairness_df['model'] == model) & (fairness_df['bias_type'] == bias_type) & (fairness_df['debiasing_method'] == debiasing_method) & (fairness_df['fairness_metric'] == metric)]\n",
    "#                 if not subset.empty:\n",
    "#                     print(f\"{debiasing_method}: {subset['score'].values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b445e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fairness score for training type one axis:\n",
      "fairness_metric          accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                                  \n",
      "no_debiasing             0.000000  0.000000  0.000000  0.000000   \n",
      "group_balance           -0.013278 -0.018615 -0.022577  0.024077   \n",
      "group_class_balance     -0.013778 -0.011734 -0.006302  0.000687   \n",
      "cda                     -0.011111 -0.011296 -0.009266  0.024185   \n",
      "dropout                 -0.011333 -0.016634 -0.038154  0.006259   \n",
      "attention_entropy       -0.012333 -0.022503 -0.025290 -0.000719   \n",
      "causal_debias           -0.014556 -0.011030 -0.012716  0.022940   \n",
      "Saliency_L1_100.0        0.041944 -0.051895 -0.176426 -0.020989   \n",
      "Saliency_L1_10.0         0.045278 -0.036721 -0.133547 -0.011092   \n",
      "Saliency_L1_1.0          0.021759 -0.031289 -0.073759  0.018616   \n",
      "Saliency_L1_0.1         -0.011167 -0.015126 -0.011201  0.021209   \n",
      "Saliency_L1_0.01        -0.013426 -0.018125 -0.021673  0.012338   \n",
      "Saliency_L2_100.0       -0.014667 -0.018133 -0.024575  0.029969   \n",
      "Saliency_L2_10.0        -0.014037 -0.019402 -0.011704  0.010965   \n",
      "Saliency_L2_1.0         -0.013130 -0.018812 -0.021648  0.010170   \n",
      "Saliency_L2_0.1         -0.014685 -0.018967 -0.016354  0.014924   \n",
      "Saliency_L2_0.01        -0.014259 -0.020669 -0.023253  0.020889   \n",
      "InputXGradient_L1_100.0  0.041944 -0.051895 -0.176426 -0.020989   \n",
      "InputXGradient_L1_10.0   0.027630 -0.033359 -0.119190 -0.013832   \n",
      "InputXGradient_L1_1.0    0.002722 -0.028668 -0.044508  0.025185   \n",
      "InputXGradient_L1_0.1   -0.014241 -0.017839 -0.021125  0.014117   \n",
      "InputXGradient_L1_0.01  -0.016667 -0.019587 -0.025161  0.009550   \n",
      "InputXGradient_L2_100.0 -0.008833 -0.010718 -0.011350  0.015564   \n",
      "InputXGradient_L2_10.0  -0.011463 -0.017962 -0.023569  0.015191   \n",
      "InputXGradient_L2_1.0   -0.011500 -0.014119 -0.019073  0.011335   \n",
      "InputXGradient_L2_0.1   -0.015093 -0.020550 -0.019724  0.014342   \n",
      "InputXGradient_L2_0.01  -0.017259 -0.022297 -0.021059  0.018376   \n",
      "raw_attention_100.0     -0.013463 -0.014187 -0.015987  0.008342   \n",
      "raw_attention_10.0      -0.013556 -0.014996 -0.011555  0.013579   \n",
      "raw_attention_1.0       -0.014907 -0.019833 -0.030748  0.017089   \n",
      "raw_attention_0.1       -0.017315 -0.020393 -0.020376  0.011958   \n",
      "raw_attention_0.01      -0.013019 -0.018064 -0.022888  0.010620   \n",
      "attention_rollout_100.0 -0.011944 -0.014181 -0.004115  0.012473   \n",
      "attention_rollout_10.0  -0.015481 -0.025169 -0.031928  0.013411   \n",
      "attention_rollout_1.0   -0.011556 -0.014124 -0.001500  0.013762   \n",
      "attention_rollout_0.1   -0.014537 -0.020444 -0.029343  0.008882   \n",
      "attention_rollout_0.01  -0.012444 -0.014805 -0.008527  0.020012   \n",
      "attention_flow_100.0    -0.014370 -0.021586 -0.027328  0.012247   \n",
      "attention_flow_10.0     -0.008981 -0.015920 -0.024042  0.009840   \n",
      "attention_flow_1.0      -0.015463 -0.022755 -0.030793  0.013934   \n",
      "attention_flow_0.1      -0.016185 -0.022851 -0.018755  0.012961   \n",
      "attention_flow_0.01     -0.014093 -0.022425 -0.035323  0.010294   \n",
      "Occlusion_100.0          0.032426 -0.060317 -0.165531 -0.005718   \n",
      "Occlusion_10.0           0.033537 -0.053568 -0.159537 -0.013322   \n",
      "Occlusion_1.0            0.038630 -0.053154 -0.163083 -0.010018   \n",
      "Occlusion_0.1            0.001741 -0.072047 -0.137971  0.003958   \n",
      "Occlusion_0.01          -0.015056 -0.018955 -0.012943  0.022960   \n",
      "\n",
      "fairness_metric          individual_fairness  \n",
      "debiasing_method                              \n",
      "no_debiasing                        0.000000  \n",
      "group_balance                       0.003755  \n",
      "group_class_balance                 0.003460  \n",
      "cda                                -0.010640  \n",
      "dropout                             0.001258  \n",
      "attention_entropy                   0.000351  \n",
      "causal_debias                       0.004412  \n",
      "Saliency_L1_100.0                  -0.016961  \n",
      "Saliency_L1_10.0                   -0.015901  \n",
      "Saliency_L1_1.0                    -0.012393  \n",
      "Saliency_L1_0.1                    -0.004304  \n",
      "Saliency_L1_0.01                    0.000284  \n",
      "Saliency_L2_100.0                  -0.006203  \n",
      "Saliency_L2_10.0                   -0.000014  \n",
      "Saliency_L2_1.0                     0.003037  \n",
      "Saliency_L2_0.1                     0.003756  \n",
      "Saliency_L2_0.01                    0.005351  \n",
      "InputXGradient_L1_100.0            -0.016955  \n",
      "InputXGradient_L1_10.0             -0.016042  \n",
      "InputXGradient_L1_1.0              -0.008719  \n",
      "InputXGradient_L1_0.1              -0.001730  \n",
      "InputXGradient_L1_0.01              0.003420  \n",
      "InputXGradient_L2_100.0            -0.003811  \n",
      "InputXGradient_L2_10.0              0.001316  \n",
      "InputXGradient_L2_1.0               0.002944  \n",
      "InputXGradient_L2_0.1               0.003868  \n",
      "InputXGradient_L2_0.01              0.005145  \n",
      "raw_attention_100.0                -0.001312  \n",
      "raw_attention_10.0                 -0.000051  \n",
      "raw_attention_1.0                   0.001108  \n",
      "raw_attention_0.1                   0.003581  \n",
      "raw_attention_0.01                  0.003564  \n",
      "attention_rollout_100.0             0.000071  \n",
      "attention_rollout_10.0              0.004172  \n",
      "attention_rollout_1.0               0.001855  \n",
      "attention_rollout_0.1               0.005064  \n",
      "attention_rollout_0.01              0.005610  \n",
      "attention_flow_100.0                0.003218  \n",
      "attention_flow_10.0                 0.003280  \n",
      "attention_flow_1.0                  0.004304  \n",
      "attention_flow_0.1                  0.004358  \n",
      "attention_flow_0.01                 0.004602  \n",
      "Occlusion_100.0                    -0.016944  \n",
      "Occlusion_10.0                     -0.016949  \n",
      "Occlusion_1.0                      -0.016850  \n",
      "Occlusion_0.1                      -0.015760  \n",
      "Occlusion_0.01                      0.006793  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show for each debiasing method, what is there average fairness score (across model types and bias types) for each metric and training type, show in one table, where each row is a debiasing method, and each column is a metric and training type\n",
    "\n",
    "for train_type in training_types:\n",
    "    print(f\"Average fairness score for training type {train_type}:\")\n",
    "    # show the difference in the average fairness score for each debiasing method compared to no debiasing\n",
    "    avg_score = fairness_df[fairness_df['training_data'] == train_type].groupby(['debiasing_method', 'fairness_metric'])['score'].mean().unstack().reset_index()\n",
    "    avg_score = avg_score.set_index('debiasing_method')\n",
    "    avg_score = avg_score.reindex(fairness_df['debiasing_method'].unique())\n",
    "    # for each debiasing method and metric, calculate the difference from no debiasing of the same metric\n",
    "    no_debiasing_scores = avg_score.loc['no_debiasing']\n",
    "    for metric in avg_score.columns:\n",
    "        if metric != 'debiasing_method':\n",
    "            avg_score[metric] = avg_score[metric] - no_debiasing_scores[metric]\n",
    "    print(avg_score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a715c321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fairness score for training type one axis:\n",
      "fairness_metric          accuracy        f1       fnr       fpr  \\\n",
      "debiasing_method                                                  \n",
      "no_debiasing             0.078056  0.094414  0.176426  0.020989   \n",
      "group_balance            0.064778  0.075799  0.153849  0.045066   \n",
      "group_class_balance      0.064278  0.082680  0.170124  0.021676   \n",
      "cda                      0.066944  0.083118  0.167160  0.045175   \n",
      "dropout                  0.066722  0.077781  0.138272  0.027248   \n",
      "attention_entropy        0.065722  0.071911  0.151135  0.020270   \n",
      "causal_debias            0.063500  0.083384  0.163709  0.043929   \n",
      "Saliency_L1_100.0        0.120000  0.042519  0.000000  0.000000   \n",
      "Saliency_L1_10.0         0.123333  0.057693  0.042879  0.009898   \n",
      "Saliency_L1_1.0          0.099815  0.063125  0.102667  0.039605   \n",
      "Saliency_L1_0.1          0.066889  0.079288  0.165225  0.042198   \n",
      "Saliency_L1_0.01         0.064630  0.076289  0.154753  0.033327   \n",
      "Saliency_L2_100.0        0.063389  0.076281  0.151851  0.050958   \n",
      "Saliency_L2_10.0         0.064019  0.075012  0.164722  0.031954   \n",
      "Saliency_L2_1.0          0.064926  0.075603  0.154778  0.031159   \n",
      "Saliency_L2_0.1          0.063370  0.075447  0.160071  0.035913   \n",
      "Saliency_L2_0.01         0.063796  0.073746  0.153173  0.041878   \n",
      "InputXGradient_L1_100.0  0.120000  0.042519  0.000000  0.000000   \n",
      "InputXGradient_L1_10.0   0.105685  0.061055  0.057236  0.007158   \n",
      "InputXGradient_L1_1.0    0.080778  0.065746  0.131918  0.046174   \n",
      "InputXGradient_L1_0.1    0.063815  0.076575  0.155301  0.035106   \n",
      "InputXGradient_L1_0.01   0.061389  0.074828  0.151265  0.030539   \n",
      "InputXGradient_L2_100.0  0.069222  0.083696  0.165076  0.036554   \n",
      "InputXGradient_L2_10.0   0.066593  0.076452  0.152856  0.036181   \n",
      "InputXGradient_L2_1.0    0.066556  0.080295  0.157353  0.032325   \n",
      "InputXGradient_L2_0.1    0.062963  0.073865  0.156702  0.035331   \n",
      "InputXGradient_L2_0.01   0.060796  0.072118  0.155367  0.039366   \n",
      "raw_attention_100.0      0.064593  0.080228  0.160438  0.029331   \n",
      "raw_attention_10.0       0.064500  0.079418  0.164871  0.034568   \n",
      "raw_attention_1.0        0.063148  0.074582  0.145678  0.038078   \n",
      "raw_attention_0.1        0.060741  0.074021  0.156050  0.032948   \n",
      "raw_attention_0.01       0.065037  0.076350  0.153537  0.031609   \n",
      "attention_rollout_100.0  0.066111  0.080233  0.172310  0.033463   \n",
      "attention_rollout_10.0   0.062574  0.069246  0.144498  0.034400   \n",
      "attention_rollout_1.0    0.066500  0.080291  0.174926  0.034752   \n",
      "attention_rollout_0.1    0.063519  0.073970  0.147083  0.029871   \n",
      "attention_rollout_0.01   0.065611  0.079609  0.167899  0.041001   \n",
      "attention_flow_100.0     0.063685  0.072828  0.149098  0.033236   \n",
      "attention_flow_10.0      0.069074  0.078494  0.152384  0.030829   \n",
      "attention_flow_1.0       0.062593  0.071659  0.145633  0.034924   \n",
      "attention_flow_0.1       0.061870  0.071563  0.157671  0.033950   \n",
      "attention_flow_0.01      0.063963  0.071989  0.141102  0.031283   \n",
      "Occlusion_100.0          0.110481  0.034097  0.010894  0.015271   \n",
      "Occlusion_10.0           0.111593  0.040846  0.016889  0.007667   \n",
      "Occlusion_1.0            0.116685  0.041260  0.013343  0.010971   \n",
      "Occlusion_0.1            0.079796  0.022367  0.038455  0.024947   \n",
      "Occlusion_0.01           0.063000  0.075459  0.163483  0.043949   \n",
      "\n",
      "fairness_metric          individual_fairness  \n",
      "debiasing_method                              \n",
      "no_debiasing                        0.016970  \n",
      "group_balance                       0.020725  \n",
      "group_class_balance                 0.020430  \n",
      "cda                                 0.006330  \n",
      "dropout                             0.018228  \n",
      "attention_entropy                   0.017321  \n",
      "causal_debias                       0.021382  \n",
      "Saliency_L1_100.0                   0.000009  \n",
      "Saliency_L1_10.0                    0.001069  \n",
      "Saliency_L1_1.0                     0.004577  \n",
      "Saliency_L1_0.1                     0.012666  \n",
      "Saliency_L1_0.01                    0.017254  \n",
      "Saliency_L2_100.0                   0.010768  \n",
      "Saliency_L2_10.0                    0.016956  \n",
      "Saliency_L2_1.0                     0.020007  \n",
      "Saliency_L2_0.1                     0.020726  \n",
      "Saliency_L2_0.01                    0.022321  \n",
      "InputXGradient_L1_100.0             0.000015  \n",
      "InputXGradient_L1_10.0              0.000928  \n",
      "InputXGradient_L1_1.0               0.008251  \n",
      "InputXGradient_L1_0.1               0.015240  \n",
      "InputXGradient_L1_0.01              0.020391  \n",
      "InputXGradient_L2_100.0             0.013159  \n",
      "InputXGradient_L2_10.0              0.018286  \n",
      "InputXGradient_L2_1.0               0.019914  \n",
      "InputXGradient_L2_0.1               0.020838  \n",
      "InputXGradient_L2_0.01              0.022116  \n",
      "raw_attention_100.0                 0.015658  \n",
      "raw_attention_10.0                  0.016919  \n",
      "raw_attention_1.0                   0.018078  \n",
      "raw_attention_0.1                   0.020552  \n",
      "raw_attention_0.01                  0.020534  \n",
      "attention_rollout_100.0             0.017041  \n",
      "attention_rollout_10.0              0.021142  \n",
      "attention_rollout_1.0               0.018825  \n",
      "attention_rollout_0.1               0.022034  \n",
      "attention_rollout_0.01              0.022580  \n",
      "attention_flow_100.0                0.020188  \n",
      "attention_flow_10.0                 0.020250  \n",
      "attention_flow_1.0                  0.021274  \n",
      "attention_flow_0.1                  0.021328  \n",
      "attention_flow_0.01                 0.021572  \n",
      "Occlusion_100.0                     0.000026  \n",
      "Occlusion_10.0                      0.000021  \n",
      "Occlusion_1.0                       0.000120  \n",
      "Occlusion_0.1                       0.001210  \n",
      "Occlusion_0.01                      0.023763  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show for each debiasing method, what is there average fairness score (across model types and bias types) for each metric and training type, show in one table, where each row is a debiasing method, and each column is a metric and training type\n",
    "\n",
    "for train_type in training_types:\n",
    "    print(f\"Average fairness score for training type {train_type}:\")\n",
    "    # show the difference in the average fairness score for each debiasing method compared to no debiasing\n",
    "    avg_score = fairness_df[fairness_df['training_data'] == train_type].groupby(['debiasing_method', 'fairness_metric'])['score'].mean().unstack().reset_index()\n",
    "    avg_score = avg_score.set_index('debiasing_method')\n",
    "    avg_score = avg_score.reindex(fairness_df['debiasing_method'].unique())\n",
    "    # for each debiasing method and metric, calculate the difference from no debiasing of the same metric\n",
    "    print(avg_score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f209a992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Saliency/L1_100.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Saliency/L1_10.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Saliency/L1_1.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Saliency/L1_0.1/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Saliency/L1_0.01/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Saliency/L2_100.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Saliency/L2_10.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Saliency/L2_1.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Saliency/L2_0.1/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Saliency/L2_0.01/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/InputXGradient/L1_100.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/InputXGradient/L1_10.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/InputXGradient/L1_1.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/InputXGradient/L1_0.1/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/InputXGradient/L1_0.01/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/InputXGradient/L2_100.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/InputXGradient/L2_10.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/InputXGradient/L2_1.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/InputXGradient/L2_0.1/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/InputXGradient/L2_0.01/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/raw_attention/100.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/raw_attention/10.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/raw_attention/1.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/raw_attention/0.1/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/raw_attention/0.01/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/attention_rollout/100.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/attention_rollout/10.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/attention_rollout/1.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/attention_rollout/0.1/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/attention_rollout/0.01/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/attention_flow/100.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/attention_flow/10.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/attention_flow/1.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/attention_flow/0.1/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/attention_flow/0.01/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Occlusion/100.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Occlusion/10.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Occlusion/1.0/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Occlusion/0.1/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_race_race_test_2000/Occlusion/0.01/fairness/fairness_race_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Saliency/L1_100.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Saliency/L1_10.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Saliency/L1_1.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Saliency/L1_0.1/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Saliency/L1_0.01/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Saliency/L2_100.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Saliency/L2_10.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Saliency/L2_1.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Saliency/L2_0.1/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Saliency/L2_0.01/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/InputXGradient/L1_100.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/InputXGradient/L1_10.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/InputXGradient/L1_1.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/InputXGradient/L1_0.1/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/InputXGradient/L1_0.01/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/InputXGradient/L2_100.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/InputXGradient/L2_10.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/InputXGradient/L2_1.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/InputXGradient/L2_0.1/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/InputXGradient/L2_0.01/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/raw_attention/100.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/raw_attention/10.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/raw_attention/1.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/raw_attention/0.1/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/raw_attention/0.01/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/attention_rollout/100.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/attention_rollout/10.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/attention_rollout/1.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/attention_rollout/0.1/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/attention_rollout/0.01/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/attention_flow/100.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/attention_flow/10.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/attention_flow/1.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/attention_flow/0.1/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/attention_flow/0.01/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Occlusion/100.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Occlusion/10.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Occlusion/1.0/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Occlusion/0.1/fairness/fairness_gender_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_gender_gender_test_2000/Occlusion/0.01/fairness/fairness_gender_test_summary_stats.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Saliency/L1_100.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Saliency/L1_10.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Saliency/L1_1.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Saliency/L1_0.1/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Saliency/L1_0.01/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Saliency/L2_100.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Saliency/L2_10.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Saliency/L2_1.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Saliency/L2_0.1/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Saliency/L2_0.01/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/InputXGradient/L1_100.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/InputXGradient/L1_10.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/InputXGradient/L1_1.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/InputXGradient/L1_0.1/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/InputXGradient/L1_0.01/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/InputXGradient/L2_100.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/InputXGradient/L2_10.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/InputXGradient/L2_1.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/InputXGradient/L2_0.1/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/InputXGradient/L2_0.01/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/raw_attention/100.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/raw_attention/10.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/raw_attention/1.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/raw_attention/0.1/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/raw_attention/0.01/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/attention_rollout/100.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/attention_rollout/10.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/attention_rollout/1.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/attention_rollout/0.1/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/attention_rollout/0.01/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/attention_flow/100.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/attention_flow/10.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/attention_flow/1.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/attention_flow/0.1/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/attention_flow/0.01/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Occlusion/100.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Occlusion/10.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Occlusion/1.0/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Occlusion/0.1/fairness/fairness_religion_test_summary_stats.json\n",
      "File not found: /scratch/yifwang/fairness_x_explainability/bias_mitigation_results_civil/bert_civil_religion_religion_test_1000/Occlusion/0.01/fairness/fairness_religion_test_summary_stats.json\n"
     ]
    }
   ],
   "source": [
    "performance_dict = {\"model\": [], \"bias_type\": [], \"debiasing_method\": [], \"training_data\": [], \"metric\": [], \"score\": []}\n",
    "for model in models:\n",
    "    for bias_type in bias_types:\n",
    "        groups = SOCIAL_GROUPS[bias_type]\n",
    "        # load baseline fairness results\n",
    "        for training_type in training_types:\n",
    "            data_token = \"all\" if training_type == \"all axes\" else bias_type\n",
    "            for debiasing_method in debiasing_methods:\n",
    "                \n",
    "                file_path = os.path.join(root_dir, f\"{model}_{data}_{data_token}_{bias_type}_test_{num_examples[bias_type]}\", debiasing_method, \"fairness\", f\"fairness_{bias_type}_test_summary_stats.json\")\n",
    "                if not os.path.exists(file_path):\n",
    "                    print(f\"File not found: {file_path}\")\n",
    "                    continue\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    fairness_data = json.load(f)\n",
    "                \n",
    "                \n",
    "                for metric in [\"accuracy\", \"f1\"]:\n",
    "                    performance_dict['model'].append(model)\n",
    "                    performance_dict['bias_type'].append(bias_type)\n",
    "                    performance_dict['debiasing_method'].append(debiasing_method)\n",
    "                    performance_dict['training_data'].append(training_type)\n",
    "                    performance_dict['metric'].append(metric)\n",
    "                    if metric in fairness_data['Metrics']['overall']:\n",
    "                        performance_dict['score'].append(fairness_data['Metrics']['overall'][metric])\n",
    "                    else:\n",
    "                        print(f\"Metric {metric} not found in fairness data for {debiasing_method} on {bias_type}\")\n",
    "                        performance_dict['score'].append(None)\n",
    "\n",
    "            for explanation_method in explanation_methods:\n",
    "                if explanation_method in [\"raw_attention\", \"attention_rollout\", \"attention_flow\", \"Occlusion\"]:\n",
    "                    aggregation = [\"none\"]\n",
    "                else:\n",
    "                    aggregation = [\"L1\", \"L2\"]\n",
    "                for aggregation_method in aggregation:\n",
    "                    for alpha in alphas:\n",
    "                        if explanation_method in [\"raw_attention\", \"attention_rollout\", \"attention_flow\", \"Occlusion\"]:\n",
    "                            file_path = os.path.join(debiased_dir, f\"{model}_{data}_{data_token}_{bias_type}_test_{num_examples[bias_type]}\", explanation_method, f\"{alpha}\",\"fairness\", f\"fairness_{bias_type}_test_summary_stats.json\")\n",
    "                        else:\n",
    "                            file_path = os.path.join(debiased_dir, f\"{model}_{data}_{data_token}_{bias_type}_test_{num_examples[bias_type]}\", explanation_method, f\"{aggregation_method}_{alpha}\",\"fairness\", f\"fairness_{bias_type}_test_summary_stats.json\")\n",
    "                        if not os.path.exists(file_path):\n",
    "                            print(f\"File not found: {file_path}\")\n",
    "                            continue\n",
    "                        with open(file_path, \"r\") as f:\n",
    "                            explanation_data = json.load(f)\n",
    "                        \n",
    "                        for metric in [\"accuracy\", \"f1\"]:\n",
    "                            performance_dict['model'].append(model)\n",
    "                            performance_dict['bias_type'].append(bias_type)\n",
    "                            if explanation_method in [\"raw_attention\", \"attention_rollout\", \"attention_flow\", \"Occlusion\"]:\n",
    "                                performance_dict['debiasing_method'].append(f\"{explanation_method}_{alpha}\")\n",
    "                            else:\n",
    "                                performance_dict['debiasing_method'].append(f\"{explanation_method}_{aggregation_method}_{alpha}\")\n",
    "                            performance_dict['training_data'].append(training_type)\n",
    "                            performance_dict['metric'].append(metric)\n",
    "                            if metric in explanation_data['Metrics']['overall']:\n",
    "                                performance_dict['score'].append(explanation_data['Metrics']['overall'][metric])\n",
    "                            else:\n",
    "                                print(f\"Metric {metric} not found in explanation data for {explanation_method} on {bias_type}\")\n",
    "                                performance_dict['score'].append(None)\n",
    "\n",
    "# convert to a pandas DataFrame\n",
    "import pandas as pd\n",
    "performance_df = pd.DataFrame(performance_dict)\n",
    "# fairness_df\n",
    "# show for each debiasing method, what is there average fairness score (across model types and bias types) for each metric and training type, show in one table, where each row is a debiasing method, and each column is a metric and training type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1707aafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average task performance for training type one axis:\n",
      "metric               accuracy        f1\n",
      "debiasing_method                       \n",
      "no_debiasing         0.000000  0.000000\n",
      "group_balance        0.003250  0.015668\n",
      "group_class_balance -0.005222 -0.001163\n",
      "cda                 -0.013333 -0.011149\n",
      "dropout             -0.002000 -0.003421\n",
      "attention_entropy   -0.002000 -0.003566\n",
      "causal_debias       -0.003278  0.000532\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_type in training_types:\n",
    "    print(f\"Average task performance for training type {train_type}:\")\n",
    "    # show the difference in the average fairness score for each debiasing method compared to no debiasing\n",
    "    avg_score = performance_df[performance_df['training_data'] == train_type].groupby(['debiasing_method', 'metric'])['score'].mean().unstack().reset_index()\n",
    "    avg_score = avg_score.set_index('debiasing_method')\n",
    "    avg_score = avg_score.reindex(performance_df['debiasing_method'].unique())\n",
    "    # for each debiasing method and metric, calculate the difference from no debiasing of the same metric\n",
    "    no_debiasing_scores = avg_score.loc['no_debiasing']\n",
    "    for metric in avg_score.columns:\n",
    "        if metric != 'debiasing_method':\n",
    "            avg_score[metric] = avg_score[metric] - no_debiasing_scores[metric]\n",
    "    print(avg_score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8d7ba50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average task performance for training type one axis:\n",
      "metric                   accuracy        f1\n",
      "debiasing_method                           \n",
      "no_debiasing              0.88050  0.837022\n",
      "group_balance             0.87250  0.828152\n",
      "group_class_balance       0.87025  0.825656\n",
      "cda                       0.86700  0.815724\n",
      "dropout                   0.88200  0.839743\n",
      "attention_entropy         0.87675  0.835940\n",
      "causal_debias             0.86175  0.798009\n",
      "Saliency_L1_100.0         0.73500  0.423631\n",
      "Saliency_L1_10.0          0.75375  0.523991\n",
      "Saliency_L1_1.0           0.83250  0.736547\n",
      "Saliency_L1_0.1           0.88175  0.843526\n",
      "Saliency_L1_0.01          0.88525  0.847557\n",
      "Saliency_L2_100.0         0.88200  0.847338\n",
      "Saliency_L2_10.0          0.88425  0.844043\n",
      "Saliency_L2_1.0           0.88725  0.850804\n",
      "Saliency_L2_0.1           0.88275  0.842559\n",
      "Saliency_L2_0.01          0.88400  0.846151\n",
      "InputXGradient_L1_100.0   0.73500  0.423631\n",
      "InputXGradient_L1_10.0    0.73525  0.424635\n",
      "InputXGradient_L1_1.0     0.88325  0.841052\n",
      "InputXGradient_L1_0.1     0.88125  0.841614\n",
      "InputXGradient_L1_0.01    0.88450  0.846103\n",
      "InputXGradient_L2_100.0   0.88175  0.847155\n",
      "InputXGradient_L2_10.0    0.88425  0.846127\n",
      "InputXGradient_L2_1.0     0.88350  0.848811\n",
      "InputXGradient_L2_0.1     0.88525  0.847758\n",
      "InputXGradient_L2_0.01    0.88350  0.846690\n",
      "raw_attention_100.0       0.87775  0.837701\n",
      "raw_attention_10.0        0.87975  0.838421\n",
      "raw_attention_1.0         0.88300  0.845933\n",
      "raw_attention_0.1         0.88900  0.853928\n",
      "raw_attention_0.01        0.88875  0.854394\n",
      "attention_rollout_100.0   0.87825  0.835280\n",
      "attention_rollout_10.0    0.87325  0.829802\n",
      "attention_rollout_1.0     0.88025  0.838543\n",
      "attention_rollout_0.1     0.88100  0.844889\n",
      "attention_rollout_0.01    0.88525  0.849429\n",
      "attention_flow_100.0      0.88400  0.846252\n",
      "attention_flow_10.0       0.88725  0.851481\n",
      "attention_flow_1.0        0.88525  0.847958\n",
      "attention_flow_0.1        0.88225  0.842101\n",
      "attention_flow_0.01       0.88825  0.854568\n",
      "Occlusion_100.0           0.73100  0.425899\n",
      "Occlusion_10.0            0.73525  0.425552\n",
      "Occlusion_1.0             0.74950  0.603738\n",
      "Occlusion_0.1             0.61125  0.514043\n",
      "Occlusion_0.01            0.88175  0.846012\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_type in training_types:\n",
    "    print(f\"Average task performance for training type {train_type}:\")\n",
    "    # show the difference in the average fairness score for each debiasing method compared to no debiasing\n",
    "    avg_score = performance_df[performance_df['training_data'] == train_type].groupby(['debiasing_method', 'metric'])['score'].mean().unstack().reset_index()\n",
    "    avg_score = avg_score.set_index('debiasing_method')\n",
    "    avg_score = avg_score.reindex(performance_df['debiasing_method'].unique())\n",
    "    print(avg_score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97c2f78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping bert, race, one axis, Saliency, L1 due to missing debiasing methods\n",
      "Skipping bert, race, one axis, Saliency, L2 due to missing debiasing methods\n",
      "Skipping bert, race, one axis, InputXGradient, L1 due to missing debiasing methods\n",
      "Skipping bert, race, one axis, InputXGradient, L2 due to missing debiasing methods\n",
      "Skipping bert, race, one axis, raw_attention, none due to missing debiasing methods\n",
      "Skipping bert, race, one axis, attention_rollout, none due to missing debiasing methods\n",
      "Skipping bert, race, one axis, attention_flow, none due to missing debiasing methods\n",
      "Skipping bert, race, one axis, Occlusion, none due to missing debiasing methods\n",
      "Skipping bert, gender, one axis, Saliency, L1 due to missing debiasing methods\n",
      "Skipping bert, gender, one axis, Saliency, L2 due to missing debiasing methods\n",
      "Skipping bert, gender, one axis, InputXGradient, L1 due to missing debiasing methods\n",
      "Skipping bert, gender, one axis, InputXGradient, L2 due to missing debiasing methods\n",
      "Skipping bert, gender, one axis, raw_attention, none due to missing debiasing methods\n",
      "Skipping bert, gender, one axis, attention_rollout, none due to missing debiasing methods\n",
      "Skipping bert, gender, one axis, attention_flow, none due to missing debiasing methods\n",
      "Skipping bert, gender, one axis, Occlusion, none due to missing debiasing methods\n",
      "Skipping bert, religion, one axis, Saliency, L1 due to missing debiasing methods\n",
      "Skipping bert, religion, one axis, Saliency, L2 due to missing debiasing methods\n",
      "Skipping bert, religion, one axis, InputXGradient, L1 due to missing debiasing methods\n",
      "Skipping bert, religion, one axis, InputXGradient, L2 due to missing debiasing methods\n",
      "Skipping bert, religion, one axis, raw_attention, none due to missing debiasing methods\n",
      "Skipping bert, religion, one axis, attention_rollout, none due to missing debiasing methods\n",
      "Skipping bert, religion, one axis, attention_flow, none due to missing debiasing methods\n",
      "Skipping bert, religion, one axis, Occlusion, none due to missing debiasing methods\n"
     ]
    }
   ],
   "source": [
    "# visualize the individual fairness scores and accuracy of the explanation debiased models in the same plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "for model in models:\n",
    "    for bias_type in bias_types:\n",
    "        for train_type in training_types:\n",
    "            all_individual_fairness_scores = {}\n",
    "            all_accuracy_scores = {}\n",
    "            all_explanation_debiased_models = {}\n",
    "            baseline_fairness = fairness_df[(fairness_df['model'] == model) & (fairness_df['bias_type'] == bias_type) & (fairness_df['training_data'] == train_type) & (fairness_df['debiasing_method'] == \"no_debiasing\") & (fairness_df[\"fairness_metric\"] == \"individual_fairness\")]['score'].values[0]\n",
    "            baseline_accuracy = performance_df[(performance_df['model'] == model) & (performance_df['bias_type'] == bias_type) & (performance_df['training_data'] == train_type) & (performance_df['debiasing_method'] == \"no_debiasing\") & (performance_df[\"metric\"] == \"accuracy\")]['score'].values[0]\n",
    "            for explanation_method in explanation_methods:\n",
    "                if explanation_method in [\"raw_attention\", \"attention_rollout\", \"attention_flow\", \"Occlusion\"]:\n",
    "                    aggregation = [\"none\"]\n",
    "                else:\n",
    "                    aggregation = [\"L1\", \"L2\"]\n",
    "                for aggregation_method in aggregation:\n",
    "                    explanation_debiased_models = [f\"{explanation_method}_{aggregation_method}_{alpha}\" if aggregation_method != \"none\" else f\"{explanation_method}_{alpha}\" for alpha in alphas]\n",
    "                    # reverse the order of the explanation_debiased_models to have the lowest alpha first\n",
    "                    explanation_debiased_models.reverse()\n",
    "                    # make sure all explanation_debiased_models are in the performance_df and fairness_df\n",
    "                    if any(explanation_debiased_model not in performance_df['debiasing_method'].unique() for explanation_debiased_model in explanation_debiased_models):\n",
    "                        print(f\"Skipping {model}, {bias_type}, {train_type}, {explanation_method}, {aggregation_method} due to missing debiasing methods\")\n",
    "                        continue\n",
    "                    individual_fairness_scores = [fairness_df[(fairness_df['model'] == model) & (fairness_df['bias_type'] == bias_type) & (fairness_df['training_data'] == train_type) & (fairness_df['debiasing_method'] == explanation_debiased_model) & (fairness_df[\"fairness_metric\"] == \"individual_fairness\")]['score'].values[0] for explanation_debiased_model in explanation_debiased_models]\n",
    "                    accuracy_scores = [performance_df[(performance_df['model'] == model) & (performance_df['bias_type'] == bias_type) & (performance_df['training_data'] == train_type) & (performance_df['debiasing_method'] == explanation_debiased_model) & (performance_df[\"metric\"] == \"accuracy\")]['score'].values[0] for explanation_debiased_model in explanation_debiased_models]\n",
    "\n",
    "                    explanation_debiasing_method = f\"{explanation_method}_{aggregation_method}\" if aggregation_method != \"none\" else explanation_method\n",
    "                    all_individual_fairness_scores[explanation_debiasing_method] = individual_fairness_scores\n",
    "                    all_accuracy_scores[explanation_debiasing_method] = accuracy_scores\n",
    "                    all_explanation_debiased_models[explanation_debiasing_method] = explanation_debiased_models\n",
    "\n",
    "            # find the maximum and minimum individual fairness scores and accuracy scores across all explanation debiased models\n",
    "            max_individual_fairness = max([max(scores) for scores in all_individual_fairness_scores.values()]+[baseline_fairness])\n",
    "            min_individual_fairness = min([min(scores) for scores in all_individual_fairness_scores.values()]+[baseline_fairness])\n",
    "            max_accuracy = max([max(scores) for scores in all_accuracy_scores.values()]+[baseline_accuracy])\n",
    "            min_accuracy = min([min(scores) for scores in all_accuracy_scores.values()]+[baseline_accuracy])\n",
    "\n",
    "            for explanation_debiasing_method in all_explanation_debiased_models.keys():\n",
    "                \n",
    "                explanation_debiased_models = all_explanation_debiased_models[explanation_debiasing_method]\n",
    "                individual_fairness_scores = all_individual_fairness_scores[explanation_debiasing_method]\n",
    "                accuracy_scores = all_accuracy_scores[explanation_debiasing_method] \n",
    "                # create two plots side by side\n",
    "                # one plot shows the individual fairness scores using a line plot with a horizontal line at the baseline individual fairness score\n",
    "                # the other plot shows the accuracy scores using a line plot with a horizontal line at the baseline accuracy score\n",
    "                # rotate x axis for better readability\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "                sns.lineplot(x=explanation_debiased_models, y=individual_fairness_scores, ax=axes[0], marker='o')\n",
    "                axes[0].axhline(y=baseline_fairness, color='r', linestyle='--', label='Baseline Individual Fairness')\n",
    "                axes[0].set_title(f'Individual Fairness Scores: {model}, {bias_type} ({train_type}) with {explanation_debiasing_method}')\n",
    "                # set x range\n",
    "                axes[0].set_ylim(min_individual_fairness-0.001, max_individual_fairness+0.001)\n",
    "                axes[0].set_xlabel('Debiasing Method')\n",
    "                axes[0].set_ylabel('Individual Fairness Score')\n",
    "                axes[0].legend()    \n",
    "                sns.lineplot(x=explanation_debiased_models, y=accuracy_scores, ax=axes[1], marker='o')\n",
    "                axes[1].axhline(y=baseline_accuracy, color='r', linestyle='--', label='Baseline Accuracy')\n",
    "\n",
    "                axes[1].set_title(f'Accuracy Scores for {model} on {bias_type} ({train_type}) with {explanation_debiasing_method}')\n",
    "\n",
    "                axes[1].set_ylim(min_accuracy-0.05, max_accuracy+0.05)\n",
    "                axes[1].set_xlabel('Debiasing Method')\n",
    "                axes[1].set_ylabel('Accuracy Score')\n",
    "                axes[1].legend()\n",
    "\n",
    "                for ax in axes:\n",
    "                    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
