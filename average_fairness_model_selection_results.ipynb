{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e87d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from utils.vocabulary import *\n",
    "\n",
    "root_dir = \"/scratch/yifwang/new_fairness_x_explainability/encoder_results\"\n",
    "models = [\"bert\", \"roberta\", \"distilbert\"]\n",
    "bias_types = [\"race\", \"gender\", \"religion\"]\n",
    "methods = [\"Attention\", \"Saliency\", \"DeepLift\", \"InputXGradient\", \"IntegratedGradients\", \"Occlusion\", \"KernelShap\"]\n",
    "debiasing_methods = [\"no_debiasing\", \"group_balance\", \"group_class_balance\", \"cda\", \"dropout\", \"attention_entropy\", \"causal_debias\"]\n",
    "training_types = [\"all axes\", \"one axis\"]\n",
    "reliance_keys = [\"raw\", \"max\", \"len\", \"norm\"]\n",
    "num_examples = {\"race\": 2000, \"gender\": 2000, \"religion\": 1000}\n",
    "fairness_metrics = [\"accuracy\", \"f1\", \"fpr\", \"fnr\", \"individual_fairness\"]\n",
    "correlation_types = [\"score\", \"rank\"]\n",
    "num_val_examples_list = {\"race\": [50, 100, 200, 500], \"gender\": [50, 100, 200, 500], \"religion\": [50, 100, 200]}\n",
    "seeds = [1, 2, 3, 4, 5, 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e70826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_selection_dict = {\"model\": [], \"bias_type\": [], \"fairness_metric\": [], \"correlation_type\": [], \"correlation\": [], \"num_val_examples\": [], \"seed\": []}\n",
    "for model in models:\n",
    "    for bias_type in bias_types:\n",
    "        for num_val_examples in num_val_examples_list[bias_type]:\n",
    "            for seed in seeds:\n",
    "                file_path = os.path.join(root_dir, \"model_selection_correlation\", f\"{model}_{bias_type}_val_{num_val_examples}_seed_{seed}_test_{num_examples[bias_type]}\", \"fairness_correlation_results.json\")\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    results = json.load(f)\n",
    "                for fairness_metric in fairness_metrics:\n",
    "                    for correlation_type in correlation_types:\n",
    "                        fairness_selection_dict[\"model\"].append(model)\n",
    "                        fairness_selection_dict[\"bias_type\"].append(bias_type)\n",
    "                        fairness_selection_dict[\"fairness_metric\"].append(fairness_metric)\n",
    "                        fairness_selection_dict[\"correlation_type\"].append(correlation_type)\n",
    "                        correlation_metric = fairness_metric if correlation_type == \"score\" else f\"{fairness_metric}_rank\"\n",
    "                        fairness_selection_dict[\"correlation\"].append(results[correlation_metric][0])\n",
    "                        fairness_selection_dict[\"num_val_examples\"].append(num_val_examples)\n",
    "                        fairness_selection_dict[\"seed\"].append(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ff0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a pandas DataFrame\n",
    "import pandas as pd\n",
    "fairness_selection_df = pd.DataFrame(fairness_selection_dict)\n",
    "#fairness_selection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6968486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation by Fairness Metric: accuracy, Correlation Type: score\n",
      "   bias_type  num_val_examples  correlation\n",
      "0     gender                50     0.068648\n",
      "1     gender               100    -0.043512\n",
      "2     gender               200    -0.112389\n",
      "3     gender               500    -0.128149\n",
      "4       race                50     0.049603\n",
      "5       race               100     0.067081\n",
      "6       race               200    -0.032839\n",
      "7       race               500     0.033678\n",
      "8   religion                50    -0.010004\n",
      "9   religion               100     0.059696\n",
      "10  religion               200     0.013115\n",
      "\n",
      "Correlation by Fairness Metric: accuracy, Correlation Type: rank\n",
      "   bias_type  num_val_examples  correlation\n",
      "0     gender                50     0.053724\n",
      "1     gender               100     0.022222\n",
      "2     gender               200     0.036386\n",
      "3     gender               500     0.063736\n",
      "4       race                50    -0.011233\n",
      "5       race               100     0.138462\n",
      "6       race               200     0.022711\n",
      "7       race               500     0.060317\n",
      "8   religion                50    -0.033700\n",
      "9   religion               100     0.125763\n",
      "10  religion               200     0.000244\n",
      "\n",
      "Correlation by Fairness Metric: f1, Correlation Type: score\n",
      "   bias_type  num_val_examples  correlation\n",
      "0     gender                50     0.059507\n",
      "1     gender               100     0.069722\n",
      "2     gender               200    -0.080376\n",
      "3     gender               500    -0.034183\n",
      "4       race                50    -0.026237\n",
      "5       race               100     0.109878\n",
      "6       race               200     0.182024\n",
      "7       race               500     0.167533\n",
      "8   religion                50     0.022057\n",
      "9   religion               100     0.038810\n",
      "10  religion               200     0.038777\n",
      "\n",
      "Correlation by Fairness Metric: f1, Correlation Type: rank\n",
      "   bias_type  num_val_examples  correlation\n",
      "0     gender                50    -0.001221\n",
      "1     gender               100    -0.044689\n",
      "2     gender               200     0.019536\n",
      "3     gender               500     0.019536\n",
      "4       race                50    -0.027839\n",
      "5       race               100    -0.010745\n",
      "6       race               200    -0.001954\n",
      "7       race               500     0.018559\n",
      "8   religion                50     0.048352\n",
      "9   religion               100     0.025153\n",
      "10  religion               200    -0.000488\n",
      "\n",
      "Correlation by Fairness Metric: fpr, Correlation Type: score\n",
      "   bias_type  num_val_examples  correlation\n",
      "0     gender                50     0.026690\n",
      "1     gender               100    -0.056142\n",
      "2     gender               200     0.062417\n",
      "3     gender               500     0.116310\n",
      "4       race                50    -0.130900\n",
      "5       race               100     0.106495\n",
      "6       race               200     0.283719\n",
      "7       race               500     0.465163\n",
      "8   religion                50     0.331359\n",
      "9   religion               100     0.389157\n",
      "10  religion               200     0.499188\n",
      "\n",
      "Correlation by Fairness Metric: fpr, Correlation Type: rank\n",
      "   bias_type  num_val_examples  correlation\n",
      "0     gender                50    -0.025885\n",
      "1     gender               100     0.074237\n",
      "2     gender               200     0.022955\n",
      "3     gender               500     0.107692\n",
      "4       race                50     0.114286\n",
      "5       race               100    -0.013187\n",
      "6       race               200     0.078632\n",
      "7       race               500     0.041270\n",
      "8   religion                50     0.084249\n",
      "9   religion               100     0.030281\n",
      "10  religion               200    -0.017582\n",
      "\n",
      "Correlation by Fairness Metric: fnr, Correlation Type: score\n",
      "   bias_type  num_val_examples  correlation\n",
      "0     gender                50    -0.027765\n",
      "1     gender               100     0.049881\n",
      "2     gender               200    -0.016274\n",
      "3     gender               500     0.163087\n",
      "4       race                50    -0.082957\n",
      "5       race               100     0.154847\n",
      "6       race               200     0.249912\n",
      "7       race               500     0.122166\n",
      "8   religion                50    -0.000250\n",
      "9   religion               100     0.017808\n",
      "10  religion               200    -0.051795\n",
      "\n",
      "Correlation by Fairness Metric: fnr, Correlation Type: rank\n",
      "   bias_type  num_val_examples  correlation\n",
      "0     gender                50    -0.115263\n",
      "1     gender               100    -0.057387\n",
      "2     gender               200     0.030037\n",
      "3     gender               500    -0.010745\n",
      "4       race                50    -0.053724\n",
      "5       race               100     0.017094\n",
      "6       race               200     0.065934\n",
      "7       race               500     0.022955\n",
      "8   religion                50    -0.124786\n",
      "9   religion               100     0.026374\n",
      "10  religion               200    -0.052747\n",
      "\n",
      "Correlation by Fairness Metric: individual_fairness, Correlation Type: score\n",
      "   bias_type  num_val_examples  correlation\n",
      "0     gender                50     0.611379\n",
      "1     gender               100     0.755976\n",
      "2     gender               200     0.822828\n",
      "3     gender               500     0.864918\n",
      "4       race                50     0.865608\n",
      "5       race               100     0.904354\n",
      "6       race               200     0.937580\n",
      "7       race               500     0.956765\n",
      "8   religion                50     0.821331\n",
      "9   religion               100     0.892306\n",
      "10  religion               200     0.921502\n",
      "\n",
      "Correlation by Fairness Metric: individual_fairness, Correlation Type: rank\n",
      "   bias_type  num_val_examples  correlation\n",
      "0     gender                50     0.051770\n",
      "1     gender               100     0.070085\n",
      "2     gender               200     0.060806\n",
      "3     gender               500     0.112576\n",
      "4       race                50     0.108913\n",
      "5       race               100     0.227106\n",
      "6       race               200     0.248840\n",
      "7       race               500     0.154090\n",
      "8   religion                50     0.182906\n",
      "9   religion               100     0.236630\n",
      "10  religion               200     0.321368\n"
     ]
    }
   ],
   "source": [
    "for fairness_metric in fairness_metrics:\n",
    "    for correlation_type in correlation_types:\n",
    "        print(f\"\\nCorrelation by Fairness Metric: {fairness_metric}, Correlation Type: {correlation_type}\")\n",
    "        average_corr_df = fairness_selection_df[(fairness_selection_df[\"fairness_metric\"] == fairness_metric) & (fairness_selection_df[\"correlation_type\"] == correlation_type)].groupby([\"bias_type\", \"num_val_examples\"])[\"correlation\"].mean().reset_index()\n",
    "        print(average_corr_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
