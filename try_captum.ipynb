{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00e64fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/yifwang/anaconda3/envs/bcos/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 13.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1, 2, 3\"\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#model.to(device)\n",
    "model.eval()\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24264dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 2025-07-01\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Task: Determine whether the following sentence contains any toxic content. Toxicity includes insults, threats, hate speech, or any language that is likely to offend or harm others.\n",
      "\n",
      "Sentence: black lives matter should research their ancestral history before blaming everybody else.\n",
      "\n",
      "Question: Does this sentence contain toxicity?\n",
      "\n",
      "Answer (Yes or No):\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.prompt import *\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "example = \"black lives matter should research their ancestral history before blaming everybody else.\"\n",
    "example = example.lower()\n",
    "text = tokenizer.apply_chat_template(fill_in_template(TEMPLATE, ZERO_SHOT_PROMPT.replace(\"[TEST EXAMPLE]\", example.lower())),tokenize=False,add_generation_prompt=True, date_string=\"2025-07-01\")\n",
    "print(text)\n",
    "#model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.model.get_input_embeddings().weight.device)\n",
    "#input_ids = model_inputs.input_ids\n",
    "#attention_mask = model_inputs.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffc20186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from captum.attr import Saliency, DeepLift, GuidedBackprop, InputXGradient, IntegratedGradients, Occlusion, ShapleyValueSampling, DeepLiftShap, GradientShap, KernelShap, FeatureAblation \n",
    "from tint.attr import SequentialIntegratedGradients\n",
    "from tqdm import tqdm\n",
    "from utils.utils import batch_loader\n",
    "\n",
    "\n",
    "class GPTEmbeddingModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(GPTEmbeddingModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, embeddings, attention_mask=None):\n",
    "        outputs = self.model(inputs_embeds=embeddings, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        logits = logits[:, -1, :]  # Get the last token's logits\n",
    "        return logits\n",
    "    \n",
    "class GPTEmbeddingModelProbWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(GPTEmbeddingModelProbWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, embeddings, attention_mask=None):\n",
    "        outputs = self.model(inputs_embeds=embeddings, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        logits = logits[:, -1, :]  # Get the last token's logits\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "        return probabilities\n",
    "    \n",
    "class GPTModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(GPTModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):       \n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        logits = logits[:, -1, :]\n",
    "        return logits\n",
    "    \n",
    "class GPTModelProbWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(GPTModelProbWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):       \n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        logits = logits[:, -1, :]\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "        return probabilities\n",
    "    \n",
    "     \n",
    "class BaseExplainer:\n",
    "\n",
    "    def _explain(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def explain(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "\n",
    "    def explain_embeddings(self, prompts, labels, targets, raw_inputs, example_indices):\n",
    "        assert len(prompts) == 1, \"Only one prompt is supported for now\"\n",
    "        inputs = self.tokenizer(prompts, return_tensors='pt', padding=True)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        if \"position_ids\" in inputs:\n",
    "            position_ids = inputs['position_ids']\n",
    "        else:\n",
    "\n",
    "            position_ids = attention_mask.long().cumsum(-1) - 1\n",
    "            position_ids.masked_fill_(attention_mask == 0, 0)\n",
    "            position_ids = position_ids.to(self.device)\n",
    "        # if targets do not start with a white space, add a white space\n",
    "        if targets is not None:\n",
    "            target_ids = [self.tokenizer(target, return_tensors='pt', add_special_tokens=False)['input_ids'][:, :1] for target in targets]\n",
    "            target_ids = torch.cat(target_ids, dim=0)\n",
    "            target_ids = target_ids.to(self.device)\n",
    "        else:\n",
    "            target_ids = None\n",
    "\n",
    "        if raw_inputs is not None:\n",
    "            for i in range(len(raw_inputs)):\n",
    "                if not raw_inputs[i].startswith(\" \"):\n",
    "                    raw_inputs[i] = \" \"+raw_inputs[i]\n",
    "            \n",
    "            raw_input_ids = self.tokenizer(raw_inputs, return_tensors='pt', padding=True, add_special_tokens=False)['input_ids']\n",
    "            raw_input_ids = raw_input_ids.to(self.device)\n",
    "        else:\n",
    "            raw_input_ids = None\n",
    "        \n",
    "        explanations = self._explain(input_ids=input_ids, attention_mask=attention_mask, position_ids=position_ids, labels=labels, target_ids=target_ids, raw_input_ids=raw_input_ids, example_indices=example_indices)\n",
    "        return explanations\n",
    "\n",
    "\n",
    "    def explain_tokens(self, prompts, labels, targets, raw_inputs, example_indices):\n",
    "        assert len(prompts) == 1, \"Only one prompt and one target is supported for now\"\n",
    "        inputs = self.tokenizer(prompts, return_tensors='pt', padding=True)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        # if targets do not start with a white space, add a white space\n",
    "        if targets is not None:\n",
    "            target_ids = [self.tokenizer(target, return_tensors='pt', add_special_tokens=False)['input_ids'][:, :1] for target in targets]\n",
    "            target_ids = torch.cat(target_ids, dim=0)\n",
    "            target_ids = target_ids.to(self.device)\n",
    "        else:\n",
    "            target_ids = None\n",
    "        if raw_inputs is not None:\n",
    "            for i in range(len(raw_inputs)):\n",
    "                if not raw_inputs[i].startswith(\" \"):\n",
    "                    raw_inputs[i] = \" \"+raw_inputs[i]\n",
    "            \n",
    "            raw_input_ids = self.tokenizer(raw_inputs, return_tensors='pt', padding=True, add_special_tokens=False)['input_ids']\n",
    "            raw_input_ids = raw_input_ids.to(self.device)\n",
    "        else:\n",
    "            raw_input_ids = None\n",
    "\n",
    "        explanations = self._explain(input_ids=input_ids, attention_mask=attention_mask, labels=labels, target_ids=target_ids, raw_input_ids=raw_input_ids, example_indices=example_indices)\n",
    "        return explanations\n",
    "    \n",
    "    \n",
    "    def explain_dataset(self, dataset):\n",
    "        # if class_labels is not provided, then num_classes must be provided\n",
    "        data_loader = batch_loader(dataset, batch_size=1, shuffle=False)\n",
    "        saliency_results = {}\n",
    "        for batch in tqdm(data_loader):\n",
    "            prompts = batch['prompt']\n",
    "            example_indices = batch['index']\n",
    "            if 'target' in batch:\n",
    "                targets = batch['target']\n",
    "            else:\n",
    "                targets = None\n",
    "            if 'raw_input' in batch:\n",
    "                raw_inputs = batch['raw_input']\n",
    "            else:\n",
    "                raw_inputs = None\n",
    "            if 'label' in batch:\n",
    "                labels = batch['label']\n",
    "            else:\n",
    "                labels = None\n",
    "            explanations = self.explain(prompts=prompts, labels=labels, targets=targets, raw_inputs=raw_inputs, example_indices=example_indices)\n",
    "            for key, value in explanations.items():\n",
    "                if key not in saliency_results:\n",
    "                    saliency_results[key] = []\n",
    "                saliency_results[key].extend(value)\n",
    "        return saliency_results\n",
    "    \n",
    "\n",
    "class BcosExplainer(BaseExplainer):\n",
    "    def __init__(self, model, tokenizer):\n",
    "\n",
    "        self.model = GPTEmbeddingModelWrapper(model)\n",
    "        self.model.eval()\n",
    "        #self.model.to(model.model.get_input_embeddings().weight.device)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = model.model.get_input_embeddings().weight.device\n",
    "\n",
    "        self.method = \"Bcos_absolute\"\n",
    "        self.positive_token = \"Yes\"\n",
    "        self.negative_token = \"No\"\n",
    "        self.positive_token_id = self.tokenizer(self.positive_token, add_special_tokens=False)[\"input_ids\"][0]\n",
    "        self.negative_token_id = self.tokenizer(self.negative_token, add_special_tokens=False)[\"input_ids\"][0]\n",
    "    \n",
    "    def _explain(self, input_ids, attention_mask, position_ids=None, labels=None, target_ids=None, raw_input_ids=None, example_indices=None):\n",
    "        \"\"\"\n",
    "        if position_ids is None:\n",
    "            position_ids = attention_mask.long().cumsum(-1) - 1\n",
    "            position_ids.masked_fill_(attention_mask == 0, 0)\n",
    "        \"\"\"\n",
    "        batch_size = input_ids.shape[0]\n",
    "        assert batch_size == 1, \"Batch size must be 1 for now\"\n",
    "\n",
    "        if hasattr(self.model.model, \"transformer\") and hasattr(self.model.model.transformer, \"wte\"):\n",
    "            wte = self.model.model.transformer.wte ## gpt model\n",
    "        elif hasattr(self.model.model, \"model\") and hasattr(self.model.model.model, \"embed_tokens\"):\n",
    "            wte = self.model.model.model.embed_tokens ## llama and qwen model\n",
    "        else:\n",
    "            raise ValueError(\"Model is not supported, cannot extract embeddings\")\n",
    "        embeddings = wte(input_ids) \n",
    "        embeddings.requires_grad_()\n",
    "\n",
    "        # Get the model's predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(embeddings, attention_mask=attention_mask)\n",
    "        probabilities = torch.softmax(outputs, dim=-1)\n",
    "        positive_prediction_probabilities = probabilities[:, self.positive_token_id]\n",
    "        negative_prediction_probabilities = probabilities[:, self.negative_token_id]\n",
    "        # get the predicted ids\n",
    "        predicted_ids = torch.where(positive_prediction_probabilities > negative_prediction_probabilities, self.positive_token_id, self.negative_token_id).unsqueeze(1)\n",
    "        \n",
    "        if target_ids is None:\n",
    "            # if target_ids is None, then use the predicted ids as target ids\n",
    "            target_ids = predicted_ids\n",
    "            \n",
    "        # get the probability of the target token\n",
    "        prediction_probabilities = probabilities[torch.arange(probabilities.shape[0]), predicted_ids].unsqueeze(1)\n",
    "\n",
    "        all_saliency_ixg_L2_results = [[] for _ in range(batch_size)]\n",
    "        all_saliency_ixg_mean_results = [[] for _ in range(batch_size)]\n",
    "\n",
    "        for explained_target_ids in target_ids:\n",
    "            explained_target_ids = explained_target_ids.unsqueeze(0)\n",
    "            target_probabilities = probabilities[torch.arange(probabilities.shape[0]), explained_target_ids].unsqueeze(1)\n",
    "            # activate explanation mode\n",
    "            with self.model.model.explanation_mode():\n",
    "                explainer_ixg = InputXGradient(self.model)\n",
    "                attributions_ixg = explainer_ixg.attribute(\n",
    "                    inputs=(embeddings),\n",
    "                    target=explained_target_ids.squeeze(),\n",
    "                    additional_forward_args=(attention_mask,)\n",
    "                )\n",
    "\n",
    "            attributions_ixg_all = attributions_ixg\n",
    "            for i in range(batch_size):\n",
    "                true_label = labels[i] if labels is not None else None\n",
    "                if raw_input_ids is not None:\n",
    "                    def find_sublist_indexes(full, sub):\n",
    "                        n, m = len(full), len(sub)\n",
    "                        for i in range(n - m + 1):\n",
    "                            if full[i:i + m] == sub:\n",
    "                                return list(range(i, i + m))\n",
    "                        return []\n",
    "                    raw_input_indexes = find_sublist_indexes(input_ids[i].detach().cpu().float().numpy().tolist(), raw_input_ids[i].detach().cpu().float().numpy().tolist())\n",
    "                    if len(raw_input_indexes) == 0:\n",
    "                        print(f\"Warning: raw_input_ids not found in input_ids for example {example_indices[i]}, return the original input\")\n",
    "                        raw_input_ids = None\n",
    "                tokens = self.tokenizer.convert_ids_to_tokens(input_ids[i].detach().cpu().float().numpy().tolist())\n",
    "                target_token = self.tokenizer.convert_ids_to_tokens(explained_target_ids[i].detach().cpu().float().numpy().tolist())[0]                 \n",
    "                prediction_token = self.tokenizer.convert_ids_to_tokens(predicted_ids[i].detach().cpu().float().numpy().tolist())[0]\n",
    "                if prediction_token == \"Yes\":\n",
    "                    predicted_class = 1\n",
    "                elif prediction_token == \"No\":\n",
    "                    predicted_class = 0\n",
    "                else:\n",
    "                    raise ValueError(f\"Warning: predicted class {prediction_token} is not Yes or No\")\n",
    "\n",
    "                if target_token == \"Yes\":\n",
    "                    target_class = 1\n",
    "                elif target_token == \"No\":\n",
    "                    target_class = 0\n",
    "                else:\n",
    "                    print(f\"Warning: target class {target_token} is not Yes or No\")\n",
    "                    target_class = target_token\n",
    "                # Compute saliency metrics for each token\n",
    "                saliency_ixg_L2 = torch.norm(attributions_ixg_all[i:i+1], dim=-1, p=2).detach().cpu().float().numpy()[0]\n",
    "                saliency_ixg_mean = attributions_ixg_all[i:i+1].mean(dim=-1).detach().cpu().float().numpy()[0]\n",
    "                # Collect results for the current example and class\n",
    "                # skip padding tokens\n",
    "                # tokens = [token for token in tokens if token != self.tokenizer.pad_token]\n",
    "                real_length = len(tokens)\n",
    "                if raw_input_ids is not None:\n",
    "                    raw_tokens = self.tokenizer.convert_ids_to_tokens(raw_input_ids[i].detach().cpu().float().numpy().tolist())\n",
    "                    raw_token_ixg_L2 = [saliency_ixg_L2.tolist()[raw_input_index] for raw_input_index in raw_input_indexes]  \n",
    "                    raw_token_ixg_mean = [saliency_ixg_mean.tolist()[raw_input_index] for raw_input_index in raw_input_indexes] \n",
    "                    raw_tokens = [token for token in raw_tokens if token != self.tokenizer.pad_token]\n",
    "                    result_ixg_L2 = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in raw_input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': f\"{self.method}_ixg_L2\",\n",
    "                        'attribution': list(zip(raw_tokens, raw_token_ixg_L2)),\n",
    "                    }\n",
    "                    result_ixg_mean = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in raw_input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': f\"{self.method}_ixg_mean\",\n",
    "                        \"attribution\": list(zip(raw_tokens, raw_token_ixg_mean)),\n",
    "                    }\n",
    "                else:\n",
    "                    result_ixg_L2 = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': f\"{self.method}_ixg_L2\",\n",
    "                        'attribution': list(zip(tokens, saliency_ixg_L2.tolist()[:real_length])),\n",
    "                    }\n",
    "\n",
    "                    result_ixg_mean = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': f\"{self.method}_ixg_mean\",\n",
    "                        \"attribution\": list(zip(tokens, saliency_ixg_mean.tolist()[:real_length])),\n",
    "                    }\n",
    "                all_saliency_ixg_L2_results[i].append(result_ixg_L2)\n",
    "                all_saliency_ixg_mean_results[i].append(result_ixg_mean)\n",
    "\n",
    "        saliency_results = {f\"{self.method}_ixg_mean\": all_saliency_ixg_mean_results}\n",
    "        return saliency_results\n",
    "    \n",
    "    def explain(self, prompts, labels, targets, raw_inputs, example_indices):\n",
    "        return self.explain_embeddings(prompts=prompts, labels=labels, targets=targets, raw_inputs=raw_inputs, example_indices=example_indices)\n",
    "    \n",
    "\n",
    "class AttentionExplainer(BaseExplainer):\n",
    "    def __init__(self, model, tokenizer, method=None, baseline='zero'):\n",
    "        # attention explainer can only explain the predicted classes\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = model.model.get_input_embeddings().weight.device\n",
    "        self.positive_token = \"Yes\"\n",
    "        self.negative_token = \"No\"\n",
    "        self.positive_token_id = self.tokenizer(self.positive_token, add_special_tokens=False)[\"input_ids\"][0]\n",
    "        self.negative_token_id = self.tokenizer(self.negative_token, add_special_tokens=False)[\"input_ids\"][0]\n",
    "\n",
    "    def _explain(self, input_ids, attention_mask, labels, target_ids, raw_input_ids, example_indices=None):\n",
    "\n",
    "        batch_size = input_ids.shape[0]\n",
    "        assert batch_size == 1, \"Batch size must be 1 for now\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # compute the probability of the target token\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1)[:, -1, :]\n",
    "        positive_prediction_probabilities = probabilities[:, self.positive_token_id]\n",
    "        negative_prediction_probabilities = probabilities[:, self.negative_token_id]\n",
    "        # get the predicted ids\n",
    "        predicted_ids = torch.where(positive_prediction_probabilities > negative_prediction_probabilities, self.positive_token_id, self.negative_token_id).unsqueeze(1)\n",
    "\n",
    "        if target_ids is None:\n",
    "            target_ids = predicted_ids\n",
    "        # get the probability of the target token\n",
    "        \n",
    "        prediction_probabilities = probabilities[torch.arange(probabilities.shape[0]), predicted_ids].unsqueeze(1)\n",
    "\n",
    "        attentions = outputs.attentions\n",
    "\n",
    "        # Stack attentions over layers\n",
    "        all_attentions = torch.stack(attentions)\n",
    "        # Get sequence length and batch size\n",
    "        seq_len = input_ids.shape[1]\n",
    "        batch_size = input_ids.shape[0]\n",
    "\n",
    "        # Expand attention mask to match attention shapes\n",
    "        # Shape: (batch_size, 1, 1, seq_len)\n",
    "        attention_mask_expanded = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # Create a mask for attention weights\n",
    "        # Shape: (batch_size, 1, seq_len, seq_len)\n",
    "        attention_mask_matrix = attention_mask_expanded * attention_mask_expanded.transpose(-1, -2)\n",
    "\n",
    "        # Mask out padding tokens in attention weights\n",
    "        # We set the attention weights corresponding to padding tokens to zero\n",
    "        all_attentions = all_attentions * attention_mask_matrix.unsqueeze(0)\n",
    "\n",
    "        # Normalize the attention weights so that they sum to 1 over the real tokens\n",
    "        # Sum over the last dimension (seq_len)\n",
    "        attn_weights_sum = all_attentions.sum(dim=-1, keepdim=True) + 1e-9  # Add epsilon to avoid division by zero\n",
    "        all_attentions = all_attentions / attn_weights_sum\n",
    "\n",
    "        # Convert input IDs back to tokens\n",
    "        tokens_batch = [self.tokenizer.convert_ids_to_tokens(ids) for ids in input_ids]\n",
    "\n",
    "        # Average Attention\n",
    "        # Average over heads\n",
    "        avg_attn_heads = all_attentions.mean(dim=2)  # Shape: (num_layers, batch_size, seq_len, seq_len)\n",
    "        # Average over layers\n",
    "        avg_attn = avg_attn_heads.mean(dim=0)  # Shape: (batch_size, seq_len, seq_len)\n",
    "\n",
    "        # Attention Rollout\n",
    "        rollout = torch.eye(seq_len).unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        rollout = rollout.to(self.device)  # Shape: (batch_size, seq_len, seq_len)\n",
    "        for attn in avg_attn_heads:\n",
    "            attn = attn + torch.eye(seq_len).unsqueeze(0).to(self.device) # Add identity for self-connections\n",
    "            attn = attn / attn.sum(dim=-1, keepdim=True)  # Normalize rows\n",
    "            rollout = torch.bmm(rollout, attn)  # Batch matrix multiplication\n",
    "        roll_next_token_attn = rollout[:, -1, :]  # Shape: (batch_size, seq_len)\n",
    "        \n",
    "        \n",
    "        # Attention Flow\n",
    "        # Take maximum over heads\n",
    "        attn_per_layer_max = all_attentions.max(dim=2)[0]  # Shape: (num_layers, batch_size, seq_len, seq_len)\n",
    "        # Initialize cumulative attention starting from [CLS]\n",
    "        cumulative_attn = torch.zeros(batch_size, seq_len)\n",
    "        cumulative_attn = cumulative_attn.to(self.device)\n",
    "        cumulative_attn[:, -1] = 1.0  # [CLS] token index is 0\n",
    "        for attn in attn_per_layer_max:\n",
    "            # attn shape: (batch_size, seq_len, seq_len)\n",
    "            # cumulative_attn shape: (batch_size, seq_len)\n",
    "            # Compute maximum attention flow to each token\n",
    "            cumulative_attn = torch.max(cumulative_attn.unsqueeze(-1) * attn, dim=1)[0]\n",
    "        flow_next_token_attn = cumulative_attn  # Shape: (batch_size, seq_len)\n",
    "\n",
    "        # Extract attention from [CLS] token\n",
    "        avg_next_token_attn = avg_attn[:, -1, :]  # Shape: (batch_size, seq_len)\n",
    "\n",
    "\n",
    "        all_raw_attention_explanations = [[] for _ in range(batch_size)]\n",
    "        all_attention_rollout_explanations = [[] for _ in range(batch_size)]\n",
    "        all_attention_flow_explanations = [[] for _ in range(batch_size)]\n",
    "\n",
    "        # For each example in the batch, print the attention scores\n",
    "        for explained_target_ids in target_ids:\n",
    "            explained_target_ids = explained_target_ids.unsqueeze(0)\n",
    "            target_probabilities = probabilities[torch.arange(probabilities.shape[0]), explained_target_ids].unsqueeze(1)\n",
    "            for i in range(batch_size):\n",
    "                true_label = labels[i] if labels is not None else None\n",
    "                if raw_input_ids is not None:\n",
    "                    def find_sublist_indexes(full, sub):\n",
    "                        n, m = len(full), len(sub)\n",
    "                        for i in range(n - m + 1):\n",
    "                            if full[i:i + m] == sub:\n",
    "                                return list(range(i, i + m))\n",
    "                        return []\n",
    "                    raw_input_indexes = find_sublist_indexes(input_ids[i].detach().cpu().float().numpy().tolist(), raw_input_ids[i].detach().cpu().float().numpy().tolist())\n",
    "                    if len(raw_input_indexes) == 0:\n",
    "                        print(f\"Warning: raw_input_ids not found in input_ids for example {example_indices[i]}, return the original input\")\n",
    "                        raw_input_ids = None\n",
    "                \n",
    "                tokens = tokens_batch[i]          \n",
    "                valid_len = attention_mask[i].sum().item()  # Number of real tokens\n",
    "                raw_attention_attribution = avg_next_token_attn[i][:int(valid_len)].cpu().float().numpy()\n",
    "                attention_rollout_attribution = roll_next_token_attn[i][:int(valid_len)].cpu().float().numpy()\n",
    "                attention_flow_attribution = flow_next_token_attn[i][:int(valid_len)].cpu().float().numpy()\n",
    "                target_token = self.tokenizer.convert_ids_to_tokens(explained_target_ids[i].detach().cpu().float().numpy().tolist())[0]  \n",
    "                prediction_token = self.tokenizer.convert_ids_to_tokens(predicted_ids[i].detach().cpu().float().numpy().tolist())[0]\n",
    "                if prediction_token == \"Yes\":\n",
    "                    predicted_class = 1\n",
    "                elif prediction_token == \"No\":\n",
    "                    predicted_class = 0\n",
    "                else:\n",
    "                    raise ValueError(f\"Warning: predicted class {prediction_token} is not Yes or No\")\n",
    "                if target_token == \"Yes\":\n",
    "                    target_class = 1\n",
    "                elif target_token == \"No\":\n",
    "                    target_class = 0\n",
    "                else:\n",
    "                    print(f\"Warning: target class {target_token} is not Yes or No\")\n",
    "                    target_class = target_token\n",
    "                if raw_input_ids is not None:\n",
    "                    raw_tokens = self.tokenizer.convert_ids_to_tokens(raw_input_ids[i].detach().cpu().float().numpy().tolist())\n",
    "                    raw_token_attention = [raw_attention_attribution.tolist()[raw_input_index] for raw_input_index in raw_input_indexes]  \n",
    "                    raw_token_attention_rollout = [attention_rollout_attribution.tolist()[raw_input_index] for raw_input_index in raw_input_indexes]\n",
    "                    raw_token_attention_flow = [attention_flow_attribution.tolist()[raw_input_index] for raw_input_index in raw_input_indexes]\n",
    "                    raw_tokens = [token for token in raw_tokens if token != self.tokenizer.pad_token]\n",
    "                    raw_attention_result = {\n",
    "                    'index': example_indices[i],\n",
    "                    'text': self.tokenizer.decode([t for t in raw_input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                    'true_label': true_label,\n",
    "                    'predicted_class': predicted_class,\n",
    "                    'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                    'target_class': target_class,\n",
    "                    'target_class_confidence': target_probabilities[i].item(),\n",
    "                    'method': 'raw_attention',\n",
    "                    'attribution': list(zip(raw_tokens, raw_token_attention)),\n",
    "                    }\n",
    "                    attention_rollout_result = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in raw_input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': 'attention_rollout',\n",
    "                        'attribution': list(zip(raw_tokens, raw_token_attention_rollout)),\n",
    "                    }\n",
    "                    attention_flow_result = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in raw_input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': 'attention_flow',\n",
    "                        'attribution': list(zip(raw_tokens, raw_token_attention_flow)),\n",
    "                    }\n",
    "                else:\n",
    "                    raw_attention_result = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': 'raw_attention',\n",
    "                        'attribution': list(zip(tokens[:int(valid_len)], raw_attention_attribution.tolist())),\n",
    "                    }    \n",
    "                    attention_rollout_result = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': 'attention_rollout',\n",
    "                        'attribution': list(zip(tokens[:int(valid_len)], attention_rollout_attribution.tolist())),\n",
    "                    }\n",
    "                    attention_flow_result = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': 'attention_flow',\n",
    "                        'attribution': list(zip(tokens[:int(valid_len)], attention_flow_attribution.tolist())),\n",
    "                    }             \n",
    "                all_raw_attention_explanations[i].append(raw_attention_result)\n",
    "                all_attention_rollout_explanations[i].append(attention_rollout_result)\n",
    "                all_attention_flow_explanations[i].append(attention_flow_result)\n",
    "        attention_explanations = {\"raw_attention\": all_raw_attention_explanations, \"attention_rollout\": all_attention_rollout_explanations, \"attention_flow\": all_attention_flow_explanations}\n",
    "        return attention_explanations\n",
    "    \n",
    "    def explain(self, prompts, labels, targets, raw_inputs, example_indices):\n",
    "        return self.explain_tokens(prompts=prompts, labels=labels, targets=targets, raw_inputs=raw_inputs, example_indices=example_indices)\n",
    "    \n",
    "    \n",
    "class GradientNPropabationExplainer(BaseExplainer):\n",
    "    def __init__(self, model, tokenizer, method='saliency', baseline='zero'):\n",
    "        self.model = GPTEmbeddingModelWrapper(model)\n",
    "        self.model.eval()\n",
    "        #self.model.to(model.model.get_input_embeddings().weight.device)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.positive_token = \"Yes\"\n",
    "        self.negative_token = \"No\"\n",
    "        self.positive_token_id = self.tokenizer(self.positive_token, add_special_tokens=False)[\"input_ids\"][0]\n",
    "        self.negative_token_id = self.tokenizer(self.negative_token, add_special_tokens=False)[\"input_ids\"][0]\n",
    "\n",
    "        self.method = method\n",
    "        if method == 'Saliency':\n",
    "            self.explainer = Saliency(self.model)\n",
    "        elif method == 'InputXGradient':\n",
    "            self.explainer = InputXGradient(self.model)\n",
    "        elif method == 'IntegratedGradients':\n",
    "            self.explainer = IntegratedGradients(self.model)\n",
    "        elif method == 'DeepLift':\n",
    "            self.explainer = DeepLift(self.model)\n",
    "        elif method == 'GuidedBackprop':\n",
    "            self.explainer = GuidedBackprop(self.model)\n",
    "        elif method == 'SIG':\n",
    "            self.explainer = SequentialIntegratedGradients(self.model)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid method {method}\")\n",
    "        self.device = model.model.get_input_embeddings().weight.device\n",
    "        if baseline == 'zero':\n",
    "            self.baseline = None\n",
    "        elif baseline == 'mask':\n",
    "            self.baseline = self.tokenizer.mask_token_id\n",
    "        elif baseline == 'pad':\n",
    "            self.baseline = self.tokenizer.pad_token_id\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid baseline {baseline}\")\n",
    "\n",
    "    def _explain(self, input_ids, attention_mask, position_ids=None, labels=None, target_ids=None, raw_input_ids=None, example_indices=None):\n",
    "        \"\"\"\n",
    "        if position_ids is None:\n",
    "            #position_ids = torch.arange(input_ids.size(1), dtype=torch.long, device=self.device).unsqueeze(0).repeat(input_ids.size(0), 1)\n",
    "            # generate according to attention mask, starting from the first non-padding token\n",
    "            position_ids = attention_mask.long().cumsum(-1) - 1\n",
    "            position_ids.masked_fill_(attention_mask == 0, 0)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = input_ids.shape[0]\n",
    "        assert batch_size == 1, \"Batch size must be 1 for now\"\n",
    "\n",
    "        if hasattr(self.model.model, \"transformer\") and hasattr(self.model.model.transformer, \"wte\"):\n",
    "            wte = self.model.model.transformer.wte ## gpt model\n",
    "        elif hasattr(self.model.model, \"model\") and hasattr(self.model.model.model, \"embed_tokens\"):\n",
    "            wte = self.model.model.model.embed_tokens ## llama model\n",
    "        else:\n",
    "            raise ValueError(\"Model is not supported, cannot extract embeddings\")\n",
    "        #wpe = self.model.model.transformer.wpe\n",
    "        embeddings = wte(input_ids) \n",
    "        embeddings.requires_grad_()\n",
    "\n",
    "        # Get the model's predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(embeddings, attention_mask=attention_mask)\n",
    "        probabilities = torch.softmax(outputs, dim=-1)\n",
    "        positive_prediction_probabilities = probabilities[:, self.positive_token_id]\n",
    "        negative_prediction_probabilities = probabilities[:, self.negative_token_id]\n",
    "        # get the predicted ids\n",
    "        predicted_ids = torch.where(positive_prediction_probabilities > negative_prediction_probabilities, self.positive_token_id, self.negative_token_id).unsqueeze(1)\n",
    "\n",
    "        if target_ids is None:\n",
    "            target_ids = predicted_ids\n",
    "            #target_ids = target_ids.unsqueeze(-1)\n",
    "        # get the probability of the target token\n",
    "        prediction_probabilities = probabilities[torch.arange(probabilities.shape[0]), predicted_ids.squeeze(1)].unsqueeze(1) # shape: [batch_size, 1]\n",
    "        \n",
    "        \n",
    "        all_saliency_L2_results = [[] for _ in range(batch_size)]\n",
    "        all_saliency_mean_results = [[] for _ in range(batch_size)]\n",
    "        \n",
    "        \n",
    "        # explain all targets\n",
    "        for explained_target_ids in target_ids:\n",
    "            explained_target_ids = explained_target_ids.unsqueeze(0)\n",
    "            target_probabilities = probabilities[torch.arange(probabilities.shape[0]), explained_target_ids.squeeze(1)].unsqueeze(1) # shape: [batch_size, 1]\n",
    "            if self.method == 'Saliency':\n",
    "                attributions = self.explainer.attribute(\n",
    "                    inputs=(embeddings),\n",
    "                    target=explained_target_ids.squeeze(),\n",
    "                    additional_forward_args=(attention_mask,),\n",
    "                    abs=False,\n",
    "                )\n",
    "            elif self.method == 'IntegratedGradients' or self.method == 'DeepLift' or self.method == 'SIG':\n",
    "                if self.baseline is not None:\n",
    "                    token_baseline_ids = torch.ones_like(input_ids) * self.baseline \n",
    "                    baselines = wte(token_baseline_ids)\n",
    "                else:\n",
    "                    baselines = None\n",
    "                attributions = self.explainer.attribute(\n",
    "                    inputs=(embeddings),\n",
    "                    baselines=baselines,\n",
    "                    target=explained_target_ids.squeeze(),\n",
    "                    additional_forward_args=(attention_mask,),\n",
    "                    n_steps=5,\n",
    "                )\n",
    "            else:\n",
    "                attributions = self.explainer.attribute(\n",
    "                    inputs=(embeddings),\n",
    "                    target=explained_target_ids.squeeze(),\n",
    "                    additional_forward_args=(attention_mask,)\n",
    "                )\n",
    "    \n",
    "            attributions_all = attributions\n",
    "\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                true_label = labels[i] if labels is not None else None\n",
    "                # find the index of the raw_input_ids in the input_ids\n",
    "                if raw_input_ids is not None:\n",
    "                    def find_sublist_indexes(full, sub):\n",
    "                        n, m = len(full), len(sub)\n",
    "                        for i in range(n - m + 1):\n",
    "                            if full[i:i + m] == sub:\n",
    "                                return list(range(i, i + m))\n",
    "                        return []\n",
    "                    raw_input_indexes = find_sublist_indexes(input_ids[i].detach().cpu().float().numpy().tolist(), raw_input_ids[i].detach().cpu().float().numpy().tolist())\n",
    "                    if len(raw_input_indexes) == 0:\n",
    "                        print(f\"Warning: raw_input_ids not found in input_ids for example {example_indices[i]}, return the original input\")\n",
    "                        raw_input_ids = None\n",
    "                tokens = self.tokenizer.convert_ids_to_tokens(input_ids[i].detach().cpu().float().numpy().tolist())\n",
    "                if raw_input_ids is not None:\n",
    "                    raw_tokens = self.tokenizer.convert_ids_to_tokens(raw_input_ids[i].detach().cpu().float().numpy().tolist())\n",
    "                target_token = self.tokenizer.convert_ids_to_tokens(explained_target_ids[i].detach().cpu().float().numpy().tolist())[0]                  \n",
    "                prediction_token = self.tokenizer.convert_ids_to_tokens(predicted_ids[i].detach().cpu().float().numpy().tolist())[0]\n",
    "                if prediction_token == \"Yes\":\n",
    "                    predicted_class = 1\n",
    "                elif prediction_token == \"No\":\n",
    "                    predicted_class = 0\n",
    "                else:\n",
    "                    raise ValueError(f\"Warning: predicted class {prediction_token} is not Yes or No\")\n",
    "                if target_token == \"Yes\":\n",
    "                    target_class = 1\n",
    "                elif target_token == \"No\":\n",
    "                    target_class = 0\n",
    "                else:\n",
    "                    print(f\"Warning: target class {target_token} is not Yes or No\")\n",
    "                    target_class = target_token\n",
    "                # Compute saliency metrics for each token\n",
    "                saliency_L2 = torch.norm(attributions_all[i:i+1], dim=-1, p=2).detach().cpu().float().numpy()[0]\n",
    "                saliency_mean = attributions_all[i:i+1].mean(dim=-1).detach().cpu().float().numpy()[0]\n",
    "                if raw_input_ids is not None:\n",
    "                    raw_token_saliency_L2 = [saliency_L2.tolist()[raw_input_index] for raw_input_index in raw_input_indexes]  \n",
    "                    raw_token_saliency_mean = [saliency_mean.tolist()[raw_input_index] for raw_input_index in raw_input_indexes] \n",
    "                    raw_tokens = [token for token in raw_tokens if token != self.tokenizer.pad_token]  \n",
    "                # Collect results for the current example and class\n",
    "                # skip padding tokens\n",
    "                # tokens = [token for token in tokens if token != self.tokenizer.pad_token]\n",
    "                 \n",
    "                \n",
    "                real_length = len(tokens)\n",
    "                if raw_input_ids is not None:\n",
    "                    result_L2 = {\n",
    "                    'index': example_indices[i],\n",
    "                    'text': self.tokenizer.decode([t for t in raw_input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                    'true_label': true_label,\n",
    "                    'predicted_class': predicted_class,\n",
    "                    'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                    'target_class': target_class,\n",
    "                    'target_class_confidence': target_probabilities[i].item(),\n",
    "                    'method': f\"{self.method}_L2\",\n",
    "                    'attribution': list(zip(raw_tokens, raw_token_saliency_L2)),\n",
    "                }\n",
    "\n",
    "                    result_mean = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in raw_input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': f\"{self.method}_mean\",\n",
    "                        \"attribution\": list(zip(raw_tokens, raw_token_saliency_mean)),\n",
    "                    }\n",
    "                    all_saliency_L2_results[i].append(result_L2)\n",
    "                    all_saliency_mean_results[i].append(result_mean)\n",
    "                else:\n",
    "                    result_L2 = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': f\"{self.method}_L2\",\n",
    "                        'attribution': list(zip(tokens, saliency_L2.tolist()[:real_length])),\n",
    "                    }\n",
    "\n",
    "                    result_mean = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': f\"{self.method}_mean\",\n",
    "                        \"attribution\": list(zip(tokens, saliency_mean.tolist()[:real_length])),\n",
    "                    }\n",
    "                    all_saliency_L2_results[i].append(result_L2)\n",
    "                    all_saliency_mean_results[i].append(result_mean)\n",
    "        saliency_results = {f\"{self.method}_L2\": all_saliency_L2_results, f\"{self.method}_mean\": all_saliency_mean_results}\n",
    "        return saliency_results\n",
    "    \n",
    "    def explain(self, prompts, labels, targets, raw_inputs, example_indices):\n",
    "        return self.explain_embeddings(prompts=prompts, labels=labels, targets=targets, raw_inputs=raw_inputs, example_indices=example_indices)\n",
    "    \n",
    "    \n",
    "class OcclusionExplainer(BaseExplainer):\n",
    "    def __init__(self, model, tokenizer, method='Occlusion', baseline='pad'):\n",
    "        self.model = GPTModelProbWrapper(model)\n",
    "        self.model.eval()\n",
    "        #self.model.to(model.model.get_input_embeddings().weight.device)\n",
    "        self.tokenizer = tokenizer\n",
    "        # self.explainer = Occlusion(self.model)\n",
    "        # we use feature ablation here because it supports ablating only specific tokens\n",
    "        self.explainer = FeatureAblation(self.model)\n",
    "        # Occlusion parameters\n",
    "        self.sliding_window_size = (1,)  # Occlude one token at a time\n",
    "        if baseline == 'zero':\n",
    "            self.baseline = None\n",
    "        elif baseline == 'mask':\n",
    "            self.baseline = self.tokenizer.mask_token_id\n",
    "        elif baseline == 'pad':\n",
    "            self.baseline = self.tokenizer.pad_token_id\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid baseline {baseline}\")\n",
    "        \n",
    "        self.positive_token = \"Yes\"\n",
    "        self.negative_token = \"No\"\n",
    "        self.positive_token_id = self.tokenizer(self.positive_token, add_special_tokens=False)[\"input_ids\"][0]\n",
    "        self.negative_token_id = self.tokenizer(self.negative_token, add_special_tokens=False)[\"input_ids\"][0]\n",
    "\n",
    "        self.stride = (1,)\n",
    "        self.device = model.model.get_input_embeddings().weight.device\n",
    "\n",
    "    def _explain(self, input_ids, attention_mask, labels=None, target_ids=None, raw_input_ids=None, example_indices=None):\n",
    "\n",
    "        batch_size = input_ids.shape[0]\n",
    "        assert batch_size == 1, \"Batch size must be 1 for now\"\n",
    "\n",
    "        # Get the model's predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probabilities = outputs\n",
    "        positive_prediction_probabilities = probabilities[:, self.positive_token_id]\n",
    "        negative_prediction_probabilities = probabilities[:, self.negative_token_id]\n",
    "        # get the predicted ids\n",
    "        predicted_ids = torch.where(positive_prediction_probabilities > negative_prediction_probabilities, self.positive_token_id, self.negative_token_id).unsqueeze(1)\n",
    "\n",
    "        if target_ids is None:\n",
    "            target_ids = predicted_ids\n",
    "        # get the probability of the target token\n",
    "        \n",
    "        prediction_probabilities = probabilities[torch.arange(probabilities.shape[0]), predicted_ids].unsqueeze(1) # shape: [batch_size, 1]\n",
    "\n",
    "        all_occlusion_results = [[] for _ in range(batch_size)]\n",
    "        \n",
    "        if raw_input_ids is not None:\n",
    "            # find the index of the raw_input_ids in the input_ids\n",
    "            def find_sublist_indexes(full, sub):\n",
    "                n, m = len(full), len(sub)\n",
    "                for i in range(n - m + 1):\n",
    "                    if full[i:i + m] == sub:\n",
    "                        return list(range(i, i + m))\n",
    "                return []\n",
    "            raw_input_indexes_list = [find_sublist_indexes(input_ids[i].detach().cpu().float().numpy().tolist(), raw_input_ids[i].detach().cpu().float().numpy().tolist()) for i in range(batch_size)]\n",
    "            if any(len(indexes) == 0 for indexes in raw_input_indexes_list):\n",
    "                print(f\"Warning: raw_input_ids not found in input_ids for some examples, returning the original input\")\n",
    "                raw_input_ids = None\n",
    "            if raw_input_ids is not None:\n",
    "                feature_masks = torch.zeros(input_ids.shape, device=self.device, dtype=torch.int32)\n",
    "                for i in range(batch_size):\n",
    "                    for j, raw_input_pos in enumerate(raw_input_indexes_list[i]):\n",
    "                        feature_masks[i, raw_input_pos] = j + 1\n",
    "            else:\n",
    "                feature_masks = None\n",
    "        else:\n",
    "            feature_masks = None\n",
    "\n",
    "        for explained_target_ids in target_ids:\n",
    "            explained_target_ids = explained_target_ids.unsqueeze(0)\n",
    "            target_probabilities = probabilities[torch.arange(probabilities.shape[0]), explained_target_ids].unsqueeze(1)\n",
    "            attributions = self.explainer.attribute(\n",
    "                inputs=input_ids,\n",
    "                feature_mask=feature_masks,\n",
    "                baselines=self.baseline,\n",
    "                target=explained_target_ids.squeeze(),\n",
    "                additional_forward_args=(attention_mask,)\n",
    "            )\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                true_label = labels[i] if labels is not None else None\n",
    "                if raw_input_ids is not None:\n",
    "                    raw_input_indexes = raw_input_indexes_list[i]\n",
    "                tokens = self.tokenizer.convert_ids_to_tokens(input_ids[i].detach().cpu().float().numpy().tolist())\n",
    "                if raw_input_ids is not None:\n",
    "                    raw_tokens = self.tokenizer.convert_ids_to_tokens(raw_input_ids[i].detach().cpu().float().numpy().tolist())\n",
    "                target_token = self.tokenizer.convert_ids_to_tokens(explained_target_ids[i].detach().cpu().float().numpy().tolist())[0]\n",
    "                prediction_token = self.tokenizer.convert_ids_to_tokens(predicted_ids[i].detach().cpu().float().numpy().tolist())[0]\n",
    "                if prediction_token == \"Yes\":\n",
    "                    predicted_class = 1\n",
    "                elif prediction_token == \"No\":\n",
    "                    predicted_class = 0\n",
    "                else:\n",
    "                    raise ValueError(f\"Warning: predicted class {prediction_token} is not Yes or No\")\n",
    "                if target_token == \"Yes\":\n",
    "                    target_class = 1\n",
    "                elif target_token == \"No\":\n",
    "                    target_class = 0\n",
    "                else:\n",
    "                    print(f\"Warning: target class {target_token} is not Yes or No\")\n",
    "                    target_class = target_token\n",
    "                attributions_i = attributions.detach().cpu().float().numpy()[i]  # Shape: [seq_len]\n",
    "                # skip padding tokens\n",
    "                # # tokens = [token for token in tokens if token != self.tokenizer.pad_token]\n",
    "                if raw_input_ids is not None:\n",
    "                    raw_token_attributions_i = [attributions_i.tolist()[raw_input_index] for raw_input_index in raw_input_indexes]  \n",
    "                    raw_tokens = [token for token in raw_tokens if token != self.tokenizer.pad_token]\n",
    "                real_length = len(tokens)\n",
    "                # Collect results for the current example and class\n",
    "\n",
    "                if raw_input_ids is not None:\n",
    "                    result = {\n",
    "                    'index': example_indices[i],\n",
    "                    'text': self.tokenizer.decode([t for t in raw_input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                    'true_label': true_label,\n",
    "                    'predicted_class': predicted_class,\n",
    "                    'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                    'target_class': target_class,\n",
    "                    'target_class_confidence': target_probabilities[i].item(),\n",
    "                    'method': 'Occlusion',\n",
    "                    'attribution': list(zip(raw_tokens, raw_token_attributions_i)),\n",
    "                }\n",
    "                    all_occlusion_results[i].append(result)\n",
    "                else:\n",
    "                    result = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': 'Occlusion',\n",
    "                        'attribution': list(zip(tokens, attributions_i.tolist()[:real_length])),\n",
    "                    }\n",
    "                    all_occlusion_results[i].append(result)\n",
    "        return {\"Occlusion\": all_occlusion_results}\n",
    "    \n",
    "    def explain(self, prompts, labels, targets, raw_inputs, example_indices):\n",
    "        return self.explain_tokens(prompts=prompts, labels=labels, targets=targets, raw_inputs=raw_inputs, example_indices=example_indices)\n",
    "    \n",
    "    \n",
    "class ShapleyValueExplainer(BaseExplainer):\n",
    "    def __init__(self, model, tokenizer, method='ShapleyValue', baseline='pad', n_samples=25):\n",
    "        self.model = GPTModelWrapper(model)\n",
    "        self.model.eval()\n",
    "        #self.model.to(model.model.get_input_embeddings().weight.device)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.n_samples = n_samples\n",
    "        self.method = method\n",
    "        if method == 'ShapleyValue':\n",
    "            self.explainer = ShapleyValueSampling(self.model)\n",
    "        elif method == 'KernelShap':\n",
    "            self.explainer = KernelShap(self.model)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid method {method}\")\n",
    "        self.device = model.model.get_input_embeddings().weight.device\n",
    "        if baseline == 'zero':\n",
    "            self.baseline = None\n",
    "        elif baseline == 'mask':\n",
    "            self.baseline = self.tokenizer.mask_token_id\n",
    "        elif baseline == 'pad':\n",
    "            self.baseline = self.tokenizer.pad_token_id if self.tokenizer.pad_token_id is not None else self.tokenizer.eos_token_id\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid baseline {baseline}\")\n",
    "        \n",
    "        self.positive_token = \"Yes\"\n",
    "        self.negative_token = \"No\"\n",
    "        self.positive_token_id = self.tokenizer(self.positive_token, add_special_tokens=False)[\"input_ids\"][0]\n",
    "        self.negative_token_id = self.tokenizer(self.negative_token, add_special_tokens=False)[\"input_ids\"][0]\n",
    "\n",
    "    def _explain(self, input_ids, attention_mask, position_ids=None, labels=None, target_ids=None, raw_input_ids=None, example_indices=None):\n",
    "        \"\"\"\n",
    "        if position_ids is None:\n",
    "            #position_ids = torch.arange(input_ids.size(1), dtype=torch.long, device=self.device).unsqueeze(0).repeat(input_ids.size(0), 1)\n",
    "            # generate according to attention mask, starting from the first non-padding token\n",
    "            position_ids = attention_mask.long().cumsum(-1) - 1\n",
    "            position_ids.masked_fill_(attention_mask == 0, 0)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = input_ids.shape[0]\n",
    "        assert batch_size == 1, \"Batch size must be 1 for now\"\n",
    "\n",
    "        # Get the model's predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "        probabilities = torch.softmax(outputs, dim=-1)\n",
    "        positive_prediction_probabilities = probabilities[:, self.positive_token_id]\n",
    "        negative_prediction_probabilities = probabilities[:, self.negative_token_id]\n",
    "        # get the predicted ids\n",
    "        predicted_ids = torch.where(positive_prediction_probabilities > negative_prediction_probabilities, self.positive_token_id, self.negative_token_id).unsqueeze(1)\n",
    "        \n",
    "        if target_ids is None:\n",
    "            target_ids = predicted_ids\n",
    "            #target_ids = target_ids.unsqueeze(-1)\n",
    "        # get the probability of the target token\n",
    "        prediction_probabilities = probabilities[torch.arange(probabilities.shape[0]), predicted_ids.squeeze(1)].unsqueeze(1) # shape: [batch_size, 1]\n",
    "        all_shap_results = [[] for _ in range(batch_size)]  \n",
    "\n",
    "        if raw_input_ids is not None:\n",
    "            # find the index of the raw_input_ids in the input_ids\n",
    "            def find_sublist_indexes(full, sub):\n",
    "                n, m = len(full), len(sub)\n",
    "                for i in range(n - m + 1):\n",
    "                    if full[i:i + m] == sub:\n",
    "                        return list(range(i, i + m))\n",
    "                return []\n",
    "            raw_input_indexes_list = [find_sublist_indexes(input_ids[i].detach().cpu().float().numpy().tolist(), raw_input_ids[i].detach().cpu().float().numpy().tolist()) for i in range(batch_size)]\n",
    "            if any(len(indexes) == 0 for indexes in raw_input_indexes_list):\n",
    "                print(f\"Warning: raw_input_ids not found in input_ids for some examples, returning the original input\")\n",
    "                raw_input_ids = None\n",
    "            if raw_input_ids is not None:\n",
    "                feature_masks = torch.zeros(input_ids.shape, device=self.device, dtype=torch.int32)\n",
    "                for i in range(batch_size):\n",
    "                    for j, raw_input_pos in enumerate(raw_input_indexes_list[i]):\n",
    "                        feature_masks[i, raw_input_pos] = j + 1\n",
    "            else:\n",
    "                feature_masks = None\n",
    "        else:\n",
    "            feature_masks = None\n",
    "\n",
    "        # explain all targets\n",
    "        for explained_target_ids in target_ids:\n",
    "            explained_target_ids = explained_target_ids.unsqueeze(0)\n",
    "            target_probabilities = probabilities[torch.arange(probabilities.shape[0]), explained_target_ids.squeeze(1)].unsqueeze(1) # shape: [batch_size, 1]\n",
    "            attributions = self.explainer.attribute(\n",
    "                inputs=input_ids,\n",
    "                baselines=self.baseline,\n",
    "                target=explained_target_ids.squeeze(),\n",
    "                additional_forward_args=(attention_mask,),\n",
    "                n_samples=self.n_samples,\n",
    "                feature_mask=feature_masks\n",
    "            )\n",
    "\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                true_label = labels[i] if labels is not None else None\n",
    "                # find the index of the raw_input_ids in the input_ids\n",
    "                if raw_input_ids is not None:\n",
    "                    raw_input_indexes = raw_input_indexes_list[i]\n",
    "                    \n",
    "                tokens = self.tokenizer.convert_ids_to_tokens(input_ids[i].detach().cpu().float().numpy().tolist())\n",
    "                if raw_input_ids is not None:\n",
    "                    raw_tokens = self.tokenizer.convert_ids_to_tokens(raw_input_ids[i].detach().cpu().float().numpy().tolist())\n",
    "                target_token = self.tokenizer.convert_ids_to_tokens(explained_target_ids[i].detach().cpu().float().numpy().tolist())[0]                  \n",
    "                prediction_token = self.tokenizer.convert_ids_to_tokens(predicted_ids[i].detach().cpu().float().numpy().tolist())[0]\n",
    "                if prediction_token == \"Yes\":\n",
    "                    predicted_class = 1\n",
    "                elif prediction_token == \"No\":\n",
    "                    predicted_class = 0\n",
    "                else:\n",
    "                    raise ValueError(f\"Warning: predicted class {prediction_token} is not Yes or No\")\n",
    "                if target_token == \"Yes\":\n",
    "                    target_class = 1\n",
    "                elif target_token == \"No\":\n",
    "                    target_class = 0\n",
    "                else:\n",
    "                    print(f\"Warning: target class {target_token} is not Yes or No\")\n",
    "                    target_class = target_token\n",
    "                # Compute saliency metrics for each token\n",
    "                attribution_i = attributions.detach().cpu().float().numpy()[i]\n",
    "                if raw_input_ids is not None:\n",
    "                    raw_token_attribution_i = [attribution_i.tolist()[raw_input_index] for raw_input_index in raw_input_indexes]  \n",
    "                    raw_tokens = [token for token in raw_tokens if token != self.tokenizer.pad_token]  \n",
    "                # Collect results for the current example and class\n",
    "                # skip padding tokens\n",
    "                # tokens = [token for token in tokens if token != self.tokenizer.pad_token]\n",
    "                 \n",
    "                \n",
    "                real_length = len(tokens)\n",
    "                if raw_input_ids is not None:\n",
    "                    result = {\n",
    "                    'index': example_indices[i],\n",
    "                    'text': self.tokenizer.decode([t for t in raw_input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                    'true_label': true_label,\n",
    "                    'predicted_class': predicted_class,\n",
    "                    'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                    'target_class': target_class,\n",
    "                    'target_class_confidence': target_probabilities[i].item(),\n",
    "                    'method': self.method,\n",
    "                    'attribution': list(zip(raw_tokens, raw_token_attribution_i)),\n",
    "                }\n",
    "\n",
    "                    \n",
    "                    all_shap_results[i].append(result)\n",
    "      \n",
    "                else:\n",
    "                    result = {\n",
    "                        'index': example_indices[i],\n",
    "                        'text': self.tokenizer.decode([t for t in input_ids[i] if not (t in self.tokenizer.all_special_ids and t != self.tokenizer.unk_token_id)], skip_special_tokens=False),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_class': predicted_class,\n",
    "                        'predicted_class_confidence': prediction_probabilities[i].item(),\n",
    "                        'target_class': target_class,\n",
    "                        'target_class_confidence': target_probabilities[i].item(),\n",
    "                        'method': self.method,\n",
    "                        'attribution': list(zip(tokens, attribution_i.tolist()[:real_length])),\n",
    "                    }\n",
    "\n",
    "                    all_shap_results[i].append(result)\n",
    "                    \n",
    "        saliency_results = {self.method: all_shap_results}\n",
    "        return saliency_results\n",
    "    \n",
    "    def explain(self, prompts, labels, targets, raw_inputs, example_indices):\n",
    "        return self.explain_tokens(prompts=prompts, labels=labels, targets=targets, raw_inputs=raw_inputs, example_indices=example_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e04e7816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black lives matter should research their ancestral history before blaming everybody else.\n"
     ]
    }
   ],
   "source": [
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa5e3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "2025-07-11 20:21:51.655752: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752258111.675699  382837 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752258111.681849  382837 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-11 20:21:51.702708: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Saliency_L2': [[{'index': 0,\n",
       "    'text': ' black lives matter should research their ancestral history before blaming everybody else.\\n\\n',\n",
       "    'true_label': None,\n",
       "    'predicted_class': 0,\n",
       "    'predicted_class_confidence': 0.9137866497039795,\n",
       "    'target_class': 0,\n",
       "    'target_class_confidence': 0.9137866497039795,\n",
       "    'method': 'Saliency_L2',\n",
       "    'attribution': [('Ġblack', 6.34375),\n",
       "     ('Ġlives', 10.8125),\n",
       "     ('Ġmatter', 11.4375),\n",
       "     ('Ġshould', 9.75),\n",
       "     ('Ġresearch', 9.5),\n",
       "     ('Ġtheir', 10.625),\n",
       "     ('Ġancestral', 8.6875),\n",
       "     ('Ġhistory', 3.75),\n",
       "     ('Ġbefore', 5.8125),\n",
       "     ('Ġblaming', 7.5625),\n",
       "     ('Ġeverybody', 10.1875),\n",
       "     ('Ġelse', 8.875),\n",
       "     ('.ĊĊ', 8.375)]}]],\n",
       " 'Saliency_mean': [[{'index': 0,\n",
       "    'text': ' black lives matter should research their ancestral history before blaming everybody else.\\n\\n',\n",
       "    'true_label': None,\n",
       "    'predicted_class': 0,\n",
       "    'predicted_class_confidence': 0.9137866497039795,\n",
       "    'target_class': 0,\n",
       "    'target_class_confidence': 0.9137866497039795,\n",
       "    'method': 'Saliency_mean',\n",
       "    'attribution': [('Ġblack', -0.0030059814453125),\n",
       "     ('Ġlives', 0.005767822265625),\n",
       "     ('Ġmatter', 0.0013885498046875),\n",
       "     ('Ġshould', 0.005126953125),\n",
       "     ('Ġresearch', -0.00131988525390625),\n",
       "     ('Ġtheir', 0.003662109375),\n",
       "     ('Ġancestral', 0.0029754638671875),\n",
       "     ('Ġhistory', -0.00113677978515625),\n",
       "     ('Ġbefore', 0.003326416015625),\n",
       "     ('Ġblaming', 0.003936767578125),\n",
       "     ('Ġeverybody', 0.00112152099609375),\n",
       "     ('Ġelse', 0.0002346038818359375),\n",
       "     ('.ĊĊ', 0.00262451171875)]}]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer = GradientNPropabationExplainer(model, tokenizer, method=\"Saliency\", baseline=\"pad\")\n",
    "#explainer = OcclusionExplainer(model, tokenizer, method=\"Occlusion\", baseline=\"pad\")\n",
    "expl = explainer.explain(\n",
    "    prompts = [text],\n",
    "    example_indices = [0],\n",
    "    labels=None,\n",
    "    targets=None,\n",
    "    raw_inputs= [example+\"\\n\\n\"]\n",
    ")\n",
    "expl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51b86f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IntegratedGradients_L2': [[{'index': 0,\n",
       "    'text': ' black lives matter should research their ancestral history before blaming everybody else.\\n\\n',\n",
       "    'true_label': None,\n",
       "    'predicted_class': 0,\n",
       "    'predicted_class_confidence': 0.9137866497039795,\n",
       "    'target_class': 0,\n",
       "    'target_class_confidence': 0.9137866497039795,\n",
       "    'method': 'IntegratedGradients_L2',\n",
       "    'attribution': [('Ġblack', 0.0651385635137558),\n",
       "     ('Ġlives', 0.10261688381433487),\n",
       "     ('Ġmatter', 0.0961100161075592),\n",
       "     ('Ġshould', 0.09998776763677597),\n",
       "     ('Ġresearch', 0.09062712639570236),\n",
       "     ('Ġtheir', 0.10869871824979782),\n",
       "     ('Ġancestral', 0.0706086978316307),\n",
       "     ('Ġhistory', 0.052381254732608795),\n",
       "     ('Ġbefore', 0.07251345366239548),\n",
       "     ('Ġblaming', 0.08444997668266296),\n",
       "     ('Ġeverybody', 0.08639474213123322),\n",
       "     ('Ġelse', 0.10483815521001816),\n",
       "     ('.ĊĊ', 0.1644434779882431)]}]],\n",
       " 'IntegratedGradients_mean': [[{'index': 0,\n",
       "    'text': ' black lives matter should research their ancestral history before blaming everybody else.\\n\\n',\n",
       "    'true_label': None,\n",
       "    'predicted_class': 0,\n",
       "    'predicted_class_confidence': 0.9137866497039795,\n",
       "    'target_class': 0,\n",
       "    'target_class_confidence': 0.9137866497039795,\n",
       "    'method': 'IntegratedGradients_mean',\n",
       "    'attribution': [('Ġblack', 4.166092548985034e-05),\n",
       "     ('Ġlives', 4.222763891448267e-05),\n",
       "     ('Ġmatter', 3.6568253563018516e-05),\n",
       "     ('Ġshould', 1.1787396942963824e-05),\n",
       "     ('Ġresearch', 5.950814374955371e-05),\n",
       "     ('Ġtheir', 1.2556371075334027e-05),\n",
       "     ('Ġancestral', 1.0948775525321253e-05),\n",
       "     ('Ġhistory', 9.968991435016505e-06),\n",
       "     ('Ġbefore', 3.2365694551117485e-06),\n",
       "     ('Ġblaming', 7.538180943811312e-05),\n",
       "     ('Ġeverybody', -1.540329321869649e-05),\n",
       "     ('Ġelse', 4.8013986088335514e-05),\n",
       "     ('.ĊĊ', -6.603763904422522e-05)]}]]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "explainer = GradientNPropabationExplainer(model, tokenizer, method=\"IntegratedGradients\", baseline=\"pad\")\n",
    "#explainer = OcclusionExplainer(model, tokenizer, method=\"Occlusion\", baseline=\"pad\")\n",
    "expl = explainer.explain(\n",
    "    prompts = [text],\n",
    "    example_indices = [0],\n",
    "    labels=None,\n",
    "    targets=None,\n",
    "    raw_inputs= [example+\"\\n\\n\"]\n",
    ")\n",
    "expl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
